{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "monetary-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "occasional-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.Pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float)\n",
    "        self.voicedExcitation = torch.tensor([], dtype = float)\n",
    "        self.VoicedExcitations = torch.tensor([], dtype = float)\n",
    "        self.f0f1s = torch.tensor([], dtype = float)\n",
    "        self.f0f1 = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.Pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "        \n",
    "        \"\"\"tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        #dur = n_fft / bin_number\n",
    "        cauchyCurve = torch.empty_like(signalsAbs)\n",
    "        gamma = 0.01\n",
    "        for i in range(signals.size()[0]):\n",
    "            f0_bin = int(tripleBatchSize / self.Pitch) #improve with time-dependent pitch data\n",
    "            f1_bin = int(2 * tripleBatchSize / self.Pitch)\n",
    "            for j in range(signals.size()[1]):\n",
    "                cauchyCurve[i][j] = signalsAbs[i][f0_bin] / (math.pi * gamma * (1 + math.pow((j - f0_bin) / gamma, 2)))\n",
    "                cauchyCurve[i][j] += signalsAbs[i][f1_bin] / (math.pi * gamma * (1 + math.pow((j - f1_bin) / gamma, 2)))\n",
    "        self.f0f1s = cauchyCurve\n",
    "        self.f0f1 = torch.mean(self.f0f1s, 0)\n",
    "        for i in range(self.f0f1s.size()[0]):\n",
    "            self.f0f1s[i] = self.f0f1s[i] - self.f0f1\"\"\"\n",
    "        \n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 10, preIterations = 2):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        #signalsAbs = torch.maximum(signalsAbs - self.f0f1, torch.zeros_like(signalsAbs)) #HERE\n",
    "        workingSpectra = torch.log(signalsAbs)\n",
    "        \n",
    "        \n",
    "        cauchyCurve = torch.empty_like(workingSpectra)\n",
    "        gamma = 1.\n",
    "        for i in range(signals.size()[0]):\n",
    "            f0_bin = int(tripleBatchSize / self.Pitch) #improve with time-dependent pitch data\n",
    "            f1_bin = int(2 * tripleBatchSize / self.Pitch)\n",
    "            for j in range(signals.size()[1]):\n",
    "                cauchyCurve[i][j] = workingSpectra[i][f0_bin] / (1 + math.pow((j - f0_bin) / gamma, 2))\n",
    "                cauchyCurve[i][j] += workingSpectra[i][f1_bin] / (1 + math.pow((j - f1_bin) / gamma, 2))\n",
    "        self.f0f1s = cauchyCurve\n",
    "        workingSpectra = torch.maximum(workingSpectra - self.f0f1s, torch.zeros_like(workingSpectra))\n",
    "        self.f0f1 = torch.mean(self.f0f1s, 0)\n",
    "        for i in range(self.f0f1s.size()[0]):\n",
    "            self.f0f1s[i] = self.f0f1s[i] - self.f0f1\n",
    "        \n",
    "        \n",
    "        \n",
    "        workingSpectra = torch.max(workingSpectra, torch.tensor([-100]))\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        \n",
    "        for j in range(preIterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.VoicedExcitations = torch.zeros_like(signals)\n",
    "        for i in range(signals.size()[0]):\n",
    "            for j in range(signals.size()[1]):\n",
    "                if torch.log(signalsAbs[i][j]) > self.spectra[i][j]:\n",
    "                    self.VoicedExcitations[i][j] = signals[i][j]\n",
    "                \n",
    "        for j in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        \n",
    "        self.f0f1 = torch.minimum(self.f0f1, self.spectrum)\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "        \n",
    "    def CalculateExcitation(self, filterWidth = 10):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        #signals = signals * (1. - self.f0f1) #HERE\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / (torch.exp(self.spectrum + self.f0f1) + torch.exp(self.spectra[i] + self.f0f1s[i]))\n",
    "            self.VoicedExcitations[i] = self.VoicedExcitations[i] / (torch.exp(self.spectrum + self.f0f1) + torch.exp(self.spectra[i] + self.f0f1s[i]))\n",
    "        \n",
    "        #VoicedExcitations = self.VoicedExcitations.abs()\n",
    "        #for i in range(filterWidth):\n",
    "        #        VoicedExcitations = torch.roll(self.VoicedExcitations.abs(), -i, dims = 1) + VoicedExcitations + torch.roll(self.VoicedExcitations.abs(), i, dims = 1)\n",
    "        #self.VoicedExcitations = self.VoicedExcitations * (self.VoicedExcitations.abs() - VoicedExcitations)\n",
    "        \n",
    "        VoicedExcitations = torch.transpose(self.VoicedExcitations, 0, 1)\n",
    "            \n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        self.voicedExcitation = torch.istft(VoicedExcitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        \n",
    "        self.excitation = self.excitation - self.voicedExcitation\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "expired-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(RelLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, targets):    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        differences = torch.abs(inputs - targets)\n",
    "        sums = torch.abs(inputs + targets)\n",
    "        out = (differences / sums).sum() / inputs.size()[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "configured-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi(nn.Module):\n",
    "    def __init__(self, learningRate=1e-5):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Conv2d(1, 10, (51, 3), padding = (25, 0), bias = False)\n",
    "        self.ReLu1 = nn.ReLU()\n",
    "        self.layer2 = torch.nn.Conv2d(10, 10, (51, 1), padding = (25, 0), bias = False)\n",
    "        self.ReLu2 = nn.ReLU()\n",
    "        self.layer3 = torch.nn.Conv2d(10, 10, (51, 1), padding = (25, 0), bias = False)\n",
    "        self.ReLu3 = nn.ReLU()\n",
    "        self.layer4 = torch.nn.Conv2d(10, 1, (51, 1), padding = (25, 0), bias = False)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        #self.criterion = nn.L1Loss()\n",
    "        self.criterion = RelLoss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.full((spectrum1.size()[0], 1), factor)\n",
    "        x = torch.cat((spectrum1.unsqueeze(1), fac, spectrum2.unsqueeze(1)), dim = 1)\n",
    "        x = x.float().unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.ReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                indexList = numpy.arange(0, data.size()[0], 1)\n",
    "                numpy.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "polished-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, SampleRate):\n",
    "        self.sampleRate = SampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def Synthesize(self, steadiness, Spectrum, Spectra, Excitation):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        self.returnSignal = torch.stft(Excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        for i in range(Spectra.size()[0]):\n",
    "            self.returnSignal[i] = self.returnSignal[i] * (torch.exp(Spectrum)[i] + math.pow(1 - steadiness, 2) * torch.exp(Spectra)[i])\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided=True, )\n",
    "        del Window\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal.detach(), 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "latin-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PhonemeSamples = dict([])\n",
    "PhonemeKeys = [\"A\", \"E\", \"I\", \"O\", \"U\", \"G\", \"K\", \"N\", \"S\", \"T\"]\n",
    "\n",
    "for key in PhonemeKeys:\n",
    "    PhonemeSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    PhonemeSamples[key].CalculatePitch(252.)\n",
    "    PhonemeSamples[key].Pitch = 385\n",
    "    PhonemeSamples[key].CalculateSpectra(iterations = 25)\n",
    "    PhonemeSamples[key].CalculateExcitation()\n",
    "\n",
    "TrainingSamples = dict([])\n",
    "TrainingKeys = [\"A_E\", \"A_G\", \"A_I\", \"A_K\", \"A_N\", \"A_O\", \"A_S\", \"A_T\", \"A_U\",\n",
    "                   \"E_A\", \"E_G\", \"E_I\", \"E_K\", \"E_N\", \"E_O\", \"E_S\", \"E_T\", \"E_U\",\n",
    "                   \"I_A\", \"I_E\", \"I_G\", \"I_K\", \"I_N\", \"I_O\", \"I_S\", \"I_T\", \"I_U\",\n",
    "                   \"O_A\", \"O_E\", \"O_G\", \"O_I\", \"O_K\", \"O_N\", \"O_S\", \"O_T\", \"O_U\",\n",
    "                   \"U_A\", \"U_E\", \"U_G\", \"U_I\", \"U_K\", \"U_N\", \"U_O\", \"U_S\", \"U_T\",\n",
    "                   \"G_A\", \"G_E\", \"G_I\", \"G_O\", \"G_U\",\n",
    "                   \"K_A\", \"K_E\", \"K_I\", \"K_O\", \"K_U\",\n",
    "                   \"N_A\", \"N_E\", \"N_I\", \"N_O\", \"N_U\",\n",
    "                   \"S_A\", \"S_E\", \"S_I\", \"S_O\", \"S_U\",\n",
    "                   \"T_A\", \"T_E\", \"T_I\", \"T_O\", \"T_U\"\n",
    "                  ]\n",
    "\n",
    "for key in TrainingKeys:\n",
    "    TrainingSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    TrainingSamples[key].CalculatePitch(252.)\n",
    "    TrainingSamples[key].CalculateSpectra(iterations = 25)\n",
    "    TrainingSamples[key].CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "former-economics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/2], loss:1.0907\n",
      "epoch [2/2], loss:1.1323\n",
      "epoch [1/2], loss:1.0689\n",
      "epoch [2/2], loss:1.0484\n",
      "epoch [1/2], loss:1.0431\n",
      "epoch [2/2], loss:1.0495\n",
      "epoch [1/2], loss:1.0355\n",
      "epoch [2/2], loss:1.0405\n",
      "epoch [1/2], loss:1.0305\n",
      "epoch [2/2], loss:1.0362\n",
      "epoch [1/2], loss:1.0457\n",
      "epoch [2/2], loss:1.0552\n",
      "epoch [1/2], loss:1.0175\n",
      "epoch [2/2], loss:1.0199\n",
      "epoch [1/2], loss:1.0221\n",
      "epoch [2/2], loss:1.0248\n",
      "epoch [1/2], loss:1.0465\n",
      "epoch [2/2], loss:1.0465\n",
      "epoch [1/2], loss:1.0585\n",
      "epoch [2/2], loss:1.0475\n",
      "epoch [1/2], loss:1.0396\n",
      "epoch [2/2], loss:1.0455\n",
      "epoch [1/2], loss:1.0389\n",
      "epoch [2/2], loss:1.0393\n",
      "epoch [1/2], loss:1.0467\n",
      "epoch [2/2], loss:1.0287\n",
      "epoch [1/2], loss:1.1975\n",
      "epoch [2/2], loss:1.0346\n",
      "epoch [1/2], loss:1.0171\n",
      "epoch [2/2], loss:1.0354\n",
      "epoch [1/2], loss:1.0434\n",
      "epoch [2/2], loss:1.0434\n",
      "epoch [1/2], loss:1.0386\n",
      "epoch [2/2], loss:1.0386\n",
      "epoch [1/2], loss:1.0414\n",
      "epoch [2/2], loss:1.0374\n",
      "epoch [1/2], loss:1.0667\n",
      "epoch [2/2], loss:1.0668\n",
      "epoch [1/2], loss:1.0480\n",
      "epoch [2/2], loss:1.0666\n",
      "epoch [1/2], loss:1.0404\n",
      "epoch [2/2], loss:1.0356\n",
      "epoch [1/2], loss:1.0217\n",
      "epoch [2/2], loss:1.0304\n",
      "epoch [1/2], loss:1.0265\n",
      "epoch [2/2], loss:1.0633\n",
      "epoch [1/2], loss:1.0518\n",
      "epoch [2/2], loss:1.0287\n",
      "epoch [1/2], loss:1.0442\n",
      "epoch [2/2], loss:1.0439\n",
      "epoch [1/2], loss:1.0361\n",
      "epoch [2/2], loss:1.0483\n",
      "epoch [1/2], loss:2.9141\n",
      "epoch [2/2], loss:1.0377\n",
      "epoch [1/2], loss:1.0229\n",
      "epoch [2/2], loss:1.0229\n",
      "epoch [1/2], loss:1.0468\n",
      "epoch [2/2], loss:1.0428\n",
      "epoch [1/2], loss:1.0421\n",
      "epoch [2/2], loss:1.0406\n",
      "epoch [1/2], loss:1.0454\n",
      "epoch [2/2], loss:1.0356\n",
      "epoch [1/2], loss:1.1348\n",
      "epoch [2/2], loss:1.0365\n",
      "epoch [1/2], loss:1.0364\n",
      "epoch [2/2], loss:1.0379\n",
      "epoch [1/2], loss:1.0488\n",
      "epoch [2/2], loss:1.0393\n",
      "epoch [1/2], loss:1.0428\n",
      "epoch [2/2], loss:1.0407\n",
      "epoch [1/2], loss:1.0614\n",
      "epoch [2/2], loss:1.0300\n",
      "epoch [1/2], loss:1.0408\n",
      "epoch [2/2], loss:1.0198\n",
      "epoch [1/2], loss:1.0256\n",
      "epoch [2/2], loss:1.0590\n",
      "epoch [1/2], loss:1.1067\n",
      "epoch [2/2], loss:1.0578\n",
      "epoch [1/2], loss:1.0526\n",
      "epoch [2/2], loss:1.0507\n",
      "epoch [1/2], loss:1.0401\n",
      "epoch [2/2], loss:1.0515\n",
      "epoch [1/2], loss:1.0489\n",
      "epoch [2/2], loss:1.0804\n",
      "epoch [1/2], loss:1.0534\n",
      "epoch [2/2], loss:1.0376\n",
      "epoch [1/2], loss:1.0504\n",
      "epoch [2/2], loss:1.0189\n",
      "epoch [1/2], loss:1.0410\n",
      "epoch [2/2], loss:1.0458\n",
      "epoch [1/2], loss:1.4439\n",
      "epoch [2/2], loss:1.0568\n",
      "epoch [1/2], loss:1.0447\n",
      "epoch [2/2], loss:1.0597\n",
      "epoch [1/2], loss:1.0669\n",
      "epoch [2/2], loss:1.0260\n",
      "epoch [1/2], loss:1.0415\n",
      "epoch [2/2], loss:1.0326\n",
      "epoch [1/2], loss:1.0497\n",
      "epoch [2/2], loss:1.0373\n",
      "epoch [1/2], loss:1.3776\n",
      "epoch [2/2], loss:1.0392\n",
      "epoch [1/2], loss:1.0482\n",
      "epoch [2/2], loss:1.0484\n",
      "epoch [1/2], loss:1.0349\n",
      "epoch [2/2], loss:1.0264\n",
      "epoch [1/2], loss:1.0424\n",
      "epoch [2/2], loss:1.0512\n",
      "epoch [1/2], loss:1.1288\n",
      "epoch [2/2], loss:1.2247\n",
      "epoch [1/2], loss:1.0386\n",
      "epoch [2/2], loss:1.0418\n",
      "epoch [1/2], loss:1.0344\n",
      "epoch [2/2], loss:1.0178\n",
      "epoch [1/2], loss:1.0166\n",
      "epoch [2/2], loss:1.0372\n",
      "epoch [1/2], loss:1.0345\n",
      "epoch [2/2], loss:1.0216\n",
      "epoch [1/2], loss:1.0167\n",
      "epoch [2/2], loss:1.0167\n",
      "epoch [1/2], loss:1.0583\n",
      "epoch [2/2], loss:1.0789\n",
      "epoch [1/2], loss:1.2023\n",
      "epoch [2/2], loss:1.0754\n",
      "epoch [1/2], loss:1.0693\n",
      "epoch [2/2], loss:1.0693\n",
      "epoch [1/2], loss:1.0277\n",
      "epoch [2/2], loss:1.0466\n",
      "epoch [1/2], loss:1.0357\n",
      "epoch [2/2], loss:1.1036\n",
      "epoch [1/2], loss:1.0438\n",
      "epoch [2/2], loss:1.0615\n",
      "epoch [1/2], loss:1.0675\n",
      "epoch [2/2], loss:1.0280\n",
      "epoch [1/2], loss:1.0521\n",
      "epoch [2/2], loss:1.0521\n",
      "epoch [1/2], loss:1.0212\n",
      "epoch [2/2], loss:1.0230\n",
      "epoch [1/2], loss:1.0811\n",
      "epoch [2/2], loss:1.0573\n"
     ]
    }
   ],
   "source": [
    "trainSpectra = []\n",
    "i = 0\n",
    "for key in TrainingKeys:\n",
    "    trainSpectra.append(torch.empty_like(TrainingSamples[key].spectra))\n",
    "    for j in range(TrainingSamples[key].spectra.size()[0]):\n",
    "        trainSpectra[i][j] = TrainingSamples[key].spectrum + TrainingSamples[key].spectra[j]\n",
    "    i += 1\n",
    "    \n",
    "specCrfAi = SpecCrfAi(learningRate=1e-5)\n",
    "for i in range(70):\n",
    "    specCrfAi.train(trainSpectra[i], epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "developmental-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testspectrum = torch.zeros(PhonemeSamples[\"A\"].spectrum.size()[0], 0)\n",
    "Testspectra = torch.zeros(PhonemeSamples[\"A\"].spectrum.size()[0], 0)\n",
    "Testexcitation = torch.tensor([])\n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i].unsqueeze(1)), dim=1)\n",
    "for i in range(50 * 1280):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(40):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"N\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"N\"].spectra[i + 0].unsqueeze(1)), dim=1)\n",
    "for i in range(0, 40 * 1280 + 0):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"N\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i + 6].unsqueeze(1)), dim=1)\n",
    "for i in range(6, 50 * 1280 + 6):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(12):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"T\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"T\"].spectra[i + 0].unsqueeze(1)), dim=1)\n",
    "for i in range(0, 12 * 1280 + 0):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"T\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i + 6].unsqueeze(1)), dim=1)\n",
    "for i in range(6, 50 * 1280 + 6):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(40, 60):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[39], Testspectrum[60], 0.05 * (i - 40))\n",
    "    \n",
    "for i in range(85, 95):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[84], Testspectrum[95], 0.1 * (i - 85))\n",
    "    \n",
    "for i in range(135, 145):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[134], Testspectrum[145], 0.1 * (i - 135))\n",
    "    \n",
    "for i in range(155, 165):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[154], Testspectrum[165], 0.1 * (i - 155))\n",
    "    \n",
    "Testspectrum = torch.transpose(Testspectrum, 0, 1)\n",
    "Testspectra = torch.transpose(Testspectra, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "flying-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = Synthesizer(PhonemeSamples[\"A\"].sampleRate)\n",
    "synthesizer.Synthesize(-1., Testspectrum, Testspectra, Testexcitation)\n",
    "synthesizer.save(\"Output_S2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "blind-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x166003a7eb0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT7UlEQVR4nO3de4xc5X3G8efx7hrjYGISL8GxDYbi0kKlBHfrgBIimqQpRjTuJaqMqhDRi0VE1KCkUmkiQfpnWiV/EEdYjoISWhrSNiS1KtOAqrQhUk2ydm2DMYSFJGWDgzcQfME29u7++sccw/js7M6ZM7d9Od+PNNpzeefMT2dmn3nnnTPnOCIEAKiOBf0uAADQWwQ/AFQMwQ8AFUPwA0DFEPwAUDGD/XrgZcuWxerVq/v18ACQpJ07d/4iIobb2Ubfgn/16tUaHR3t18MDQJJs/7TdbTDUAwAVQ/ADQMUQ/ABQMQQ/AFQMwQ8AFUPwA0DFEPwAUDFJB/+JU1P6153j4tTSAFBc337A1Qmff+gpffmRH+u8xUN6/6+/rd/lAEASku7xHzzyqiTpyInJPlcCAOlIOvgBAK0j+AGgYgh+AKgYgh8AKobgB4CKIfgBoGIIfgComKbBb3uR7R/Y3mN7n+2/bdDGtu+yPWZ7r+213SkXANCuIr/cfVXS+yLiqO0hSd+3/WBE7Khrs17Smuz2Lkl3Z38BAPNM0x5/1BzNZoeyW/7kOBsk3Zu13SFpqe3lnS0VANAJhcb4bQ/Y3i3poKSHI+LRXJMVkp6rmx/PluW3s8n2qO3RiYmJkiUDANpRKPgjYioi3ilppaR1tn8j18SN7tZgO1sjYiQiRoaHh1suFgDQvpaO6omIlyX9l6TrcqvGJa2qm18p6fl2CgMAdEeRo3qGbS/Nps+W9AFJT+aabZN0U3Z0z1WSDkXEgU4XCwBoX5GjepZL+prtAdXeKP45Iv7d9i2SFBFbJG2XdL2kMUnHJN3cpXrPwPVXAKB1TYM/IvZKurLB8i110yHp1s6WBgDohqR/uetGXykDAOaUdPADAFpH8ANAxRD8AFAxBD8AVAzBDwAVQ/ADQMUQ/ABQMQQ/AFRM0sHPKRsAoHVJBz8AoHUEPwBUDMEPABWTdPBzkjYAaF3SwQ8AaB3BDwAVQ/ADQMUQ/ABQMQQ/AFQMwQ8AFZN08HPKBgBoXdLBDwBoXdPgt73K9ndt77e9z/YnGrS51vYh27uz2x3dKRcA0K7BAm0mJX0qInbZXiJpp+2HI+KJXLtHIuKGzpcIAOikpj3+iDgQEbuy6SOS9kta0e3CAADd0dIYv+3Vkq6U9GiD1Vfb3mP7QdtXzHL/TbZHbY9OTEy0Xi0AoG2Fg9/2OZK+Kem2iDicW71L0kUR8Q5JX5T07UbbiIitETESESPDw8MlSwYAtKNQ8NseUi3074uIB/LrI+JwRBzNprdLGrK9rKOVAgA6oshRPZb0FUn7I+ILs7S5IGsn2+uy7b7YyUIbP263HwEA3niKHNXzbkkfkfSY7d3Zsk9LulCSImKLpA9L+pjtSUnHJW2M4OdVADAfNQ3+iPi+pDn71hGxWdLmThUFAOgefrkLABVD8ANAxSQd/HyLAACtSzr4AQCtSzb4/+Pxn+vpg0f7XQYAJKfI4Zzz0i3/uLPfJQBAkpLt8QMAyiH4AaBiCH4AqBiCHwAqhuAHgIoh+AGgYgh+AKgYgh8AKobgB4CKIfgBoGIIfgCoGIIfACqG4AeAiiH4AaBiCH4AqBiCHwAqpmnw215l+7u299veZ/sTDdrY9l22x2zvtb22O+UCANpV5Apck5I+FRG7bC+RtNP2wxHxRF2b9ZLWZLd3Sbo7+wsAmGea9vgj4kBE7Mqmj0jaL2lFrtkGSfdGzQ5JS20v73i1AIC2tTTGb3u1pCslPZpbtULSc3Xz45r55iDbm2yP2h6dmJhosVQAQCcUDn7b50j6pqTbIuJwfnWDu8SMBRFbI2IkIkaGh4dbqxQA0BGFgt/2kGqhf19EPNCgybikVXXzKyU93355AIBOK3JUjyV9RdL+iPjCLM22SbopO7rnKkmHIuJAB+sEAHRIkaN63i3pI5Ies707W/ZpSRdKUkRskbRd0vWSxiQdk3RzxysFAHRE0+CPiO+r8Rh+fZuQdGunigIAdA+/3AWAiiH4AaBiCH4AqJgkg7/2lQIAoIwkgx8AUF6SwU+HHwDKSzP4Z8zzTgAARaUZ/HT5AaC0NIM/P8/7AAAUlmTw5xH8AFBcksFP0ANAeWkGf26wh/cBACguzeAn6QGgtCSDP4+jfACguCSDn5wHgPKSDP483gcAoLgkg59f6gJAeWkG/8xzNgAACkoz+PtdAAAkLM3gj/xx/LwVAEBRSQY/AKC8JIOfk7QBQHlNg9/2PbYP2n58lvXX2j5ke3d2u6PzZZ4pH/TkPgAUN1igzVclbZZ07xxtHomIGzpSUREkPQCU1rTHHxHfk/RSD2opbMZJ2ngjAIDCOjXGf7XtPbYftH3FbI1sb7I9ant0YmKiQw8NAGhFJ4J/l6SLIuIdkr4o6duzNYyIrRExEhEjw8PDpR9w5hg/XX4AKKrt4I+IwxFxNJveLmnI9rK2K5vrMbu5cQB4g2s7+G1fYNvZ9Lpsmy+2u925zPgBF+8EAFBY06N6bH9d0rWSltkel3SnpCFJiogtkj4s6WO2JyUdl7QxunyCfHIeAMprGvwRcWOT9ZtVO9yzb3gjAIDi0vzlLkkPAKWlGfz5Pj7vBABQWJLBz9gOAJSXZPBzHRYAKC/J4AcAlJdk8M/45S5dfgAoLM3gn3GSNpIfAIpKM/jJeQAoLc3gbzIPAJhdmsFPlx8ASksy+PN4HwCA4pIMfoIeAMpLMvjzeB8AgOKSDH56/ABQXprBz3H8AFBaksEPACgvyeCngw8A5aUZ/P0uAAASlmbwc7F1ACgtzeCfMU/yA0BRSQY/AKC8JIOf8/EDQHlNg9/2PbYP2n58lvW2fZftMdt7ba/tfJl5JD0AlFWkx/9VSdfNsX69pDXZbZOku9sva24zevzdfkAAeANpGvwR8T1JL83RZIOke6Nmh6Sltpd3qsCGNXVz4wDwBteJMf4Vkp6rmx/Pls1ge5PtUdujExMTHXjoGsb4AaC4TgS/GyxrGMURsTUiRiJiZHh4uPQDEvQAUF4ngn9c0qq6+ZWSnu/Admc14yRtDP4AQGGdCP5tkm7Kju65StKhiDjQge3Oih4/AJQ32KyB7a9LulbSMtvjku6UNCRJEbFF0nZJ10sak3RM0s3dKvY0juMHgPKaBn9E3NhkfUi6tWMVFcDQDgCUl+QvdwEA5SUZ/AztAEB5SQZ/HpdeBIDikgx+vtwFgPLSDH6+3AWA0pIM/jzeBgCguCSDn6EdACgvzeDPz/NGAACFpRn8JD0AlJZm8M+Y540AAIpKMvjzpsl9ACgsyeDPj/RMk/wAUFiSwZ8f7JlmzB8ACksy+PMd/CmCHwAKSzP4c8lP7gNAcUkGfz7npxjjB4DCkgz+/Jg+Y/wAUFySwc9RPQBQXpLBP7PH36dCACBBiQb/mfMc1QMAxSUa/LkeP11+ACgsyeDPn6SNL3cBoLhCwW/7OttP2R6zfXuD9dfaPmR7d3a7o/Olvm56+sz5qenG7QAAMw02a2B7QNKXJP2OpHFJP7S9LSKeyDV9JCJu6EKNM+R7+JymGQCKK9LjXydpLCKejYiTku6XtKG7Zc1txg+4CH4AKKxI8K+Q9Fzd/Hi2LO9q23tsP2j7ikYbsr3J9qjt0YmJiRLl1swc4y+9KQConCLB7wbL8lG7S9JFEfEOSV+U9O1GG4qIrRExEhEjw8PDLRVaLx/0HNUDAMUVCf5xSavq5ldKer6+QUQcjoij2fR2SUO2l3WsyhxO2QAA5RUJ/h9KWmP7YtsLJW2UtK2+ge0LbDubXpdt98VOF3vajB9w0eMHgMKaHtUTEZO2Py7pO5IGJN0TEfts35Kt3yLpw5I+ZntS0nFJG6OLh9owxg8A5TUNfum14ZvtuWVb6qY3S9rc2dJmx1APAJSX5C938z/gIvgBoLg0gz8X9IzxA0BxSQZ/voNPhx8Aiksy+Cen6fEDQFmJBv+Zg/yM8QNAcWkG/xRH9QBAWWkG/4wef58KAYAEJRn8p6YY4weAspIM/tNBf+6iQS0cWMD5+AGgBUkG/2R2ya09d35Q71mzjPPxA0ALkgz+U9OhoQHLthbYM77sBQDMLsngn5ya1uCCWumLhhbo1UkuugsARSUZ/CdOTWvRUK30xQsHdOzkZJ8rAoB0JBr8U1o0NCBJWrxwUMdOTvW5IgBIR5rBPzldF/wDOk7wA0BhaQb/qSmdNfj6UM/kdOgk4/wAUEiSwX/4+Cmde/aQJOnshbVrydDrB4Bikgz+Xx47qbcsXiip1uOXpGOn+IIXAIpIMvhfeuWUzntTLfiXZj3/F4+e7GdJAJCM5II/IvTysZM6b3Et8JcvPVuSdODQiX6WBQDJSC74x395XJPToZXnLZYkvX3pIknSz355rJ9lAUAykgv+J39+RJJ02QVLJEnD55ylt75pofb+7FA/ywKAZBQKftvX2X7K9pjt2xust+27svV7ba/tfKk1q9+6WH/5vktfC37bumbNMj287wW9fIxxfgBopmnw2x6Q9CVJ6yVdLulG25fnmq2XtCa7bZJ0d4frfM2aty3RJz94mc45a/C1ZX/x3kt0/NSUNm7doft/8H/a89zLOnjkhI6dnOSUzQCQM9i8idZJGouIZyXJ9v2SNkh6oq7NBkn3Ri1ld9heant5RBzoeMUNXPH2N+vLN43ozm37dPsDj52xzpYWDQ5oYIG1wNLAAmfTr/+1NeM+Z8zLTdbn7+851+cXzFiPysi/VlANG39rlf78mkv69vhFgn+FpOfq5sclvatAmxWSzgh+25tU+0SgCy+8sNVa5/Tbv3a+rr1sWM9MHNWzE6/ohcMn9MrJKb3y6qROnJrS1HTt2rxT06GpCE1Pvz59hrlnZ3yCmLm+vfujQnjyK2vZOWf19fGLBH+jLkn+JVukjSJiq6StkjQyMtLxl71tXXr+El16/pJObxoA3jCKfLk7LmlV3fxKSc+XaAMAmAeKBP8PJa2xfbHthZI2StqWa7NN0k3Z0T1XSTrUq/F9AEBrmg71RMSk7Y9L+o6kAUn3RMQ+27dk67dI2i7pekljko5Jurl7JQMA2lFkjF8RsV21cK9ftqVuOiTd2tnSAADdkNwvdwEA7SH4AaBiCH4AqBiCHwAqxv06l43tCUk/LXn3ZZJ+0cFyOo36ypvPtUnU1475XJs0v+urr+2iiBhuZ2N9C/522B6NiJF+1zEb6itvPtcmUV875nNt0vyur9O1MdQDABVD8ANAxaQa/Fv7XUAT1FfefK5Nor52zOfapPldX0drS3KMHwBQXqo9fgBASQQ/AFRMcsHf7MLvPXj8Vba/a3u/7X22P5Et/6ztn9nend2ur7vP32T1PmX7d3tQ409sP5bVMZote4vth20/nf09rx/12b6sbh/ttn3Y9m392n+277F90Pbjdcta3le2fzPb52O273KHrqk4S31/b/tJ23ttf8v20mz5atvH6/bhlrr79LK+lp/LbtQ3S23fqKvrJ7Z3Z8t7uu/myJHevPYiIpmbaqeFfkbSJZIWStoj6fIe17Bc0tpseomkH6l2EfrPSvqrBu0vz+o8S9LFWf0DXa7xJ5KW5Zb9naTbs+nbJX2uX/Xlns+fS7qoX/tP0nslrZX0eDv7StIPJF2t2tXoHpS0vov1fVDSYDb9ubr6Vte3y22nl/W1/Fx2o75GteXWf17SHf3Yd5o9R3ry2kutx//ahd8j4qSk0xd+75mIOBARu7LpI5L2q3Z94dlskHR/RLwaET9W7ZoF67pfacM6vpZNf03S79ct71d975f0TETM9QvurtYXEd+T9FKDxyy8r2wvl3RuRPxP1P4T7627T8fri4iHImIym92h2hXvZtXr+ubQ0/03V21Zr/iPJX19rm10sbbZcqQnr73Ugn+2i7r3he3Vkq6U9Gi26OPZx+976j6i9aPmkPSQ7Z2uXeBekt4W2VXRsr/n97G+0zbqzH+8+bL/Wt1XK7LpXtZ42p+q1ss77WLb/2v7v21fky3rR32tPJf9qO8aSS9ExNN1y/qy73I50pPXXmrBX+ii7r1g+xxJ35R0W0QclnS3pF+R9E5JB1T7GCn1p+Z3R8RaSesl3Wr7vXO07cs+de0ynh+S9C/Zovm0/2YzWy392oefkTQp6b5s0QFJF0bElZI+KemfbJ/bh/pafS77sf9u1Jmdjr7suwY5MmvTWeooVV9qwT8vLupue0i1J+u+iHhAkiLihYiYiohpSV/W68MRPa85Ip7P/h6U9K2slheyj4WnP74e7Fd9mfWSdkXEC1mt82b/qfV9Na4zh1u6XqPtj0q6QdKfZB/xlQ0DvJhN71RtHPhXe11fieeyp/XZHpT0h5K+UVdzz/ddoxxRj157qQV/kQu/d1U2NvgVSfsj4gt1y5fXNfsDSaePJNgmaaPts2xfLGmNal/GdKu+N9lecnpatS8CH8/q+GjW7KOS/q0f9dU5o8c1X/Zf3WMW3lfZR/Ijtq/KXh831d2n42xfJ+mvJX0oIo7VLR+2PZBNX5LV92wf6mvpuex1fZI+IOnJiHhtiKTX+262HFGvXnvtfjvd65tqF3X/kWrvyJ/pw+O/R7WPUnsl7c5u10v6B0mPZcu3SVped5/PZPU+pQ4dTTFHfZeo9u3/Hkn7Tu8jSW+V9J+Sns7+vqUf9WWPt1jSi5LeXLesL/tPtTefA5JOqdZ7+rMy+0rSiGoB94ykzcp+Fd+l+sZUG+89/frbkrX9o+w53yNpl6Tf61N9LT+X3aivUW3Z8q9KuiXXtqf7TrPnSE9ee5yyAQAqJrWhHgBAmwh+AKgYgh8AKobgB4CKIfgBoGIIfgCoGIIfACrm/wHkwn1cV+tpwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(PhonemeSamples[\"A\"].f0f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "polish-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16609be83d0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(PhonemeSamples[\"A\"].spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-heater",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
