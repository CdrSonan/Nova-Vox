{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jokla\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float)\n",
    "        self.voicedExcitation = torch.tensor([], dtype = float)\n",
    "        self.VoicedExcitations = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "        \n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 10, preIterations = 2):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        \n",
    "        workingSpectra = torch.sqrt(signalsAbs)\n",
    "        \n",
    "        workingSpectra = torch.max(workingSpectra, torch.tensor([-100]))\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        \n",
    "        for j in range(preIterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.VoicedExcitations = torch.zeros_like(signals)\n",
    "        for i in range(signals.size()[0]):\n",
    "            for j in range(signals.size()[1]):\n",
    "                if torch.sqrt(signalsAbs[i][j]) > self.spectra[i][j]:\n",
    "                    self.VoicedExcitations[i][j] = signals[i][j]\n",
    "                \n",
    "        for j in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        #return torch.log(signalsAbs)\n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "        \n",
    "    def CalculateExcitation(self, filterWidth = 10):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "            self.VoicedExcitations[i] = self.VoicedExcitations[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "        \n",
    "        VoicedExcitations = torch.transpose(self.VoicedExcitations, 0, 1)\n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        self.voicedExcitation = torch.istft(VoicedExcitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        \n",
    "        self.excitation = self.excitation - self.voicedExcitation\n",
    "        self.excitation = torch.stft(self.excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        \n",
    "        self.excitation = torch.transpose(self.excitation, 0, 1)\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expired-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(RelLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, targets):    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        differences = torch.abs(inputs - targets)\n",
    "        sums = torch.abs(inputs + targets)\n",
    "        out = (differences / sums).sum() / inputs.size()[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configured-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi(nn.Module):\n",
    "    def __init__(self, learningRate=1e-4):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Linear(3843, 3843)\n",
    "        self.ReLu1 = nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(3843, 5763)\n",
    "        self.ReLu2 = nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(5763, 3842)\n",
    "        self.ReLu3 = nn.ReLU()\n",
    "        self.layer4 = torch.nn.Linear(3842, 1921)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #self.criterion = RelLoss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.tensor([factor])\n",
    "        x = torch.cat((spectrum1, spectrum2, fac), dim = 0)\n",
    "        x = x.float()#.unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.ReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        output = torch.square(torch.squeeze(self(torch.sqrt(spectrum1), torch.sqrt(spectrum2), factor)))\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                indexList = np.arange(0, data.size()[0], 1)\n",
    "                np.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "black-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSegment:\n",
    "    def __init__(self, start1, start2, start3, end1, end2, end3, startCap, endCap, phonemeKey, vb, offset, repetititionSpacing, pitch, steadiness):\n",
    "        self.start1 = start1\n",
    "        self.start2 = start2\n",
    "        self.start3 = start3\n",
    "        self.end1 = end1\n",
    "        self.end2 = end2\n",
    "        self.end3 = end3\n",
    "        self.startCap = startCap\n",
    "        self.endCap = endCap\n",
    "        self.phonemeKey = phonemeKey\n",
    "        self.vb = vb\n",
    "        self.offset = offset\n",
    "        self.repetititionSpacing = repetititionSpacing\n",
    "        self.pitch = pitch\n",
    "        self.steadiness = steadiness\n",
    "        \n",
    "    def getSpectrum(self):\n",
    "        if self.startCap:\n",
    "            windowStart = self.offset\n",
    "        else:\n",
    "            windowStart = self.start3 - self.start1 + self.offset\n",
    "        if self.endCap:\n",
    "            windowEnd = self.end3 - self.start1 + self.offset\n",
    "        else:\n",
    "            windowEnd = self.end1 - self.start1 + self.offset\n",
    "        spectrum =  self.vb.phonemeDict[self.phonemeKey].spectrum#implement looping\n",
    "        spectra =  self.vb.phonemeDict[self.phonemeKey].spectra[windowStart:windowEnd]\n",
    "        return torch.square(spectrum + (math.pow(1 - self.steadiness, 2) * spectra))\n",
    "    \n",
    "    def getExcitation(self):\n",
    "        BatchSize = int(self.vb.sampleRate / 75)\n",
    "        tripleBatchSize = int(self.vb.sampleRate / 25)\n",
    "        premul = self.vb.phonemeDict[self.phonemeKey].excitation.size()[0] / (self.end3 - self.start1 + 1)\n",
    "        #premul = 1\n",
    "        if self.startCap:\n",
    "            windowStart = 0#math.floor(self.offset)\n",
    "            length = -self.start1\n",
    "        else:\n",
    "            windowStart = math.floor((self.start2 - self.start1) * premul)# + self.offset)\n",
    "            length = -self.start2\n",
    "        if self.endCap:\n",
    "            windowEnd = math.ceil((self.end3 - self.start1) * premul)# + self.offset)\n",
    "            length += self.end3\n",
    "        else:\n",
    "            windowEnd = math.ceil((self.end2 - self.start1) * premul)# + self.offset)\n",
    "            length += self.end2\n",
    "        excitation = self.vb.phonemeDict[self.phonemeKey].excitation[windowStart:windowEnd]\n",
    "        excitation = torch.transpose(excitation, 0, 1)\n",
    "        transform = torchaudio.transforms.TimeStretch(hop_length = int(self.vb.sampleRate / 75),\n",
    "                                                      n_freq = int(self.vb.sampleRate / 25 / 2) + 1, \n",
    "                                                      fixed_rate = premul)\n",
    "        excitation = transform(torch.view_as_real(excitation))\n",
    "        excitation = torch.view_as_complex(excitation)\n",
    "        window = torch.hann_window(int(self.vb.sampleRate / 25))\n",
    "        excitation = torch.istft(excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = window, onesided = True, length = length*int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        \"\"\"slope = torch.linspace(0, 1, (self.start3 - self.start1) * int(self.vb.sampleRate / 75))\n",
    "        voicedExcitation[0:(self.start3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        slope = torch.linspace(1, 0, (self.end3 - self.end1) * int(self.vb.sampleRate / 75))\n",
    "        voicedExcitation[(self.end1 - self.start1) * int(self.vb.sampleRate / 75):(self.end3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\"\"\"\n",
    "        \n",
    "        return excitation[0:length*int(self.vb.sampleRate / 75)]\n",
    "    \n",
    "    def getVoicedExcitation(self):\n",
    "        nativePitch = self.vb.phonemeDict[self.phonemeKey].pitch\n",
    "        #nativePitch = self.vb.phonemeDict[self.phonemeKey].pitches[...]\n",
    "        #pitch = nativePitch + self.vb.phonemeDict[phonemeKey].pitches...\n",
    "        premul = self.pitch / nativePitch * self.vb.sampleRate / 75\n",
    "        windowStart = math.floor(self.offset * premul)\n",
    "        windowEnd = math.ceil((self.end3 - self.start1 + self.offset) * premul)\n",
    "        voicedExcitation = self.vb.phonemeDict[self.phonemeKey].voicedExcitation[windowStart:windowEnd]\n",
    "        transform = torchaudio.transforms.Resample(orig_freq = nativePitch,#self.pitch,\n",
    "                                                   new_freq = self.pitch,#nativePitch,\n",
    "                                                   resampling_method = 'sinc_interpolation')\n",
    "        voicedExcitation = transform(voicedExcitation)\n",
    "        if self.startCap == False:\n",
    "            slope = torch.linspace(0, 1, (self.start3 - self.start1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[0:(self.start3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        if self.endCap == False:\n",
    "            slope = torch.linspace(1, 0, (self.end3 - self.end1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[(self.end1 - self.start1) * int(self.vb.sampleRate / 75):(self.end3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        \n",
    "        return voicedExcitation[0:(self.end3 - self.start1) * int(self.vb.sampleRate / 75)]\n",
    "        #resample segments\n",
    "        #individual fourier transform\n",
    "        #istft\n",
    "        #windowing adaptive to borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSequence:\n",
    "    def __init__(self, start, end, vb, borders, phonemes, offsets):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.vb = vb\n",
    "        self.synth = Synthesizer(self.vb.sampleRate)\n",
    "        \n",
    "        self.spectrum = torch.zeros((self.end - self.start, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "        self.excitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        self.voicedExcitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        self.segments = []\n",
    "        if len(phonemes)== 1:#rewrite border system to use tensor, implement pitch and steadiness\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, True, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "        else:\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, False, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "            for i in range(1, len(phonemes)-1):\n",
    "                self.segments.append(VocalSegment(borders[3*i], borders[3*i+1], borders[3*i+2], borders[3*i+3], borders[3*i+4], borders[3*i+5],\n",
    "                                                  False, False, phonemes[i], vb, offsets[i], None, 386, 0))\n",
    "            endpoint = len(phonemes)-1\n",
    "            self.segments.append(VocalSegment(borders[3*endpoint], borders[3*endpoint+1], borders[3*endpoint+2], borders[3*endpoint+3], borders[3*endpoint+4], borders[3*endpoint+5],\n",
    "                                             False, True, phonemes[-1], vb, offsets[-1], None, 386, 0))\n",
    "\n",
    "        self.requiresUpdate = np.ones(len(phonemes))\n",
    "        self.update()\n",
    "    def update(self):\n",
    "        for i in range(self.requiresUpdate.size):\n",
    "            if self.requiresUpdate[i] == 1:\n",
    "                print(i)\n",
    "                segment = self.segments[i]\n",
    "                spectrum = torch.zeros((segment.end3 - segment.start1, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "                excitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                voicedExcitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = segment.start3 - segment.start1\n",
    "                    previousSpectrum = self.segments[i-1].getSpectrum()[-1]\n",
    "                    previousVoicedExcitation = self.segments[i-1].getVoicedExcitation()[(self.segments[i-1].end1-self.segments[i-1].end3)*int(self.vb.sampleRate/75):]\n",
    "                if segment.endCap:\n",
    "                    windowEnd = segment.end3 - segment.start1\n",
    "                else:\n",
    "                    windowEnd = segment.end1 - segment.start1\n",
    "                    nextSpectrum = self.segments[i+1].getSpectrum()[0]\n",
    "                    nextVoicedExcitation = self.segments[i-1].getVoicedExcitation()[0:(self.segments[i+1].start3-self.segments[i+1].start1)*int(self.vb.sampleRate/75)]\n",
    "                \n",
    "                spectrum[windowStart:windowEnd] = segment.getSpectrum()\n",
    "                voicedExcitation = segment.getVoicedExcitation()\n",
    "                if segment.startCap == False:\n",
    "                    for j in range(segment.start3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(previousSpectrum, spectrum[windowStart], j / (segment.start3 - segment.start1))\n",
    "                    voicedExcitation[0:(segment.start3-segment.start1)*int(self.vb.sampleRate/75)] += previousVoicedExcitation\n",
    "                if segment.endCap == False:\n",
    "                    for j in range(segment.end1 - segment.start1, segment.end3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(spectrum[windowEnd], nextSpectrum, (j - segment.start1) / (segment.end3 - segment.end1))\n",
    "                    voicedExcitation[(segment.end1-segment.end3)*int(self.vb.sampleRate/75):] += nextVoicedExcitation\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = (segment.start2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    previousExcitation = self.segments[i-1].getExcitation()[(segment.start1-segment.start2)*int(self.vb.sampleRate/75):]\n",
    "                    excitation[0:windowStart] = previousExcitation\n",
    "                if segment.endCap:\n",
    "                    windowEnd = (segment.end3 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                else:\n",
    "                    windowEnd = (segment.end2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    nextExcitation = self.segments[i+1].getExcitation()[0:(segment.end3-segment.end2)*int(self.vb.sampleRate/75)]\n",
    "                    excitation[windowEnd:] = nextExcitation\n",
    "                excitation[windowStart:windowEnd] = segment.getExcitation()\n",
    "                \n",
    "                self.spectrum[segment.start1:segment.end3] = spectrum\n",
    "                self.excitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = excitation\n",
    "                self.voicedExcitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = voicedExcitation\n",
    "                \n",
    "                skipPrevious = True#implement skipPrevious\n",
    "            else:\n",
    "                skipPrevious = False\n",
    "            \n",
    "        self.synth.Synthesize(0, self.spectrum, self.excitation, self.voicedExcitation)\n",
    "    def save(self):\n",
    "        self.synth.save(\"Output_Demo.wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valid-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempVB:\n",
    "    def __init__(self):\n",
    "        self.sampleRate = 48000\n",
    "        self.phonemeDict = dict([])\n",
    "        phonemeKeys = [\"A\", \"E\", \"I\", \"O\", \"U\", \"G\", \"K\", \"N\", \"S\", \"T\"]\n",
    "        for key in phonemeKeys:\n",
    "            self.phonemeDict[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "            self.sampleRate = self.phonemeDict[key].sampleRate\n",
    "            self.phonemeDict[key].CalculatePitch(249.)\n",
    "            self.phonemeDict[key].CalculateSpectra(iterations = 15)\n",
    "            self.phonemeDict[key].CalculateExcitation()\n",
    "        self.crfAi = SpecCrfAi(learningRate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voicebank:\n",
    "    def __init__(self, vbKey):\n",
    "        self.phonemeDict = dict()\n",
    "        loaded_weights = 0#(vbKey)\n",
    "        self.crfAi = 0#SpecCrfAi(loaded_weights)\n",
    "        #load additional parameters\n",
    "        self.sampleRate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polished-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, sampleRate):\n",
    "        self.sampleRate = sampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def Synthesize(self, steadiness, spectrum, Excitation, VoicedExcitation):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        \n",
    "        #HERE + VoicedExcitation\n",
    "        \n",
    "        self.returnSignal = torch.stft(Excitation + VoicedExcitation , tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)[0:-1]\n",
    "        self.returnSignal = self.returnSignal * spectrum\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided=True)\n",
    "        del Window\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal.detach(), 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latin-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSamples = dict([])\n",
    "TrainingKeys = [\"A_E\", \"A_G\", \"A_I\", \"A_K\", \"A_N\", \"A_O\", \"A_S\", \"A_T\", \"A_U\",\n",
    "                   \"E_A\", \"E_G\", \"E_I\", \"E_K\", \"E_N\", \"E_O\", \"E_S\", \"E_T\", \"E_U\",\n",
    "                   \"I_A\", \"I_E\", \"I_G\", \"I_K\", \"I_N\", \"I_O\", \"I_S\", \"I_T\", \"I_U\",\n",
    "                   \"O_A\", \"O_E\", \"O_G\", \"O_I\", \"O_K\", \"O_N\", \"O_S\", \"O_T\", \"O_U\",\n",
    "                   \"U_A\", \"U_E\", \"U_G\", \"U_I\", \"U_K\", \"U_N\", \"U_O\", \"U_S\", \"U_T\",\n",
    "                   \"G_A\", \"G_E\", \"G_I\", \"G_O\", \"G_U\",\n",
    "                   \"K_A\", \"K_E\", \"K_I\", \"K_O\", \"K_U\",\n",
    "                   \"N_A\", \"N_E\", \"N_I\", \"N_O\", \"N_U\",\n",
    "                   \"S_A\", \"S_E\", \"S_I\", \"S_O\", \"S_U\",\n",
    "                   \"T_A\", \"T_E\", \"T_I\", \"T_O\", \"T_U\"\n",
    "                  ]\n",
    "\n",
    "for key in TrainingKeys:\n",
    "    TrainingSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    TrainingSamples[key].CalculatePitch(249.)\n",
    "    TrainingSamples[key].CalculateSpectra(iterations = 25)\n",
    "    TrainingSamples[key].CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "former-economics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5], loss:0.6224\n",
      "epoch [2/5], loss:0.3106\n",
      "epoch [3/5], loss:0.1755\n",
      "epoch [4/5], loss:0.1556\n",
      "epoch [5/5], loss:0.1464\n",
      "epoch [1/5], loss:0.1791\n",
      "epoch [2/5], loss:0.2703\n",
      "epoch [3/5], loss:0.0806\n",
      "epoch [4/5], loss:0.0671\n",
      "epoch [5/5], loss:0.1091\n",
      "epoch [1/5], loss:0.1536\n",
      "epoch [2/5], loss:0.3959\n",
      "epoch [3/5], loss:0.4011\n",
      "epoch [4/5], loss:0.1501\n",
      "epoch [5/5], loss:0.1937\n",
      "epoch [1/5], loss:0.1868\n",
      "epoch [2/5], loss:0.0241\n",
      "epoch [3/5], loss:0.1321\n",
      "epoch [4/5], loss:0.0176\n",
      "epoch [5/5], loss:0.1693\n",
      "epoch [1/5], loss:0.1159\n",
      "epoch [2/5], loss:0.0943\n",
      "epoch [3/5], loss:0.0837\n",
      "epoch [4/5], loss:0.1130\n",
      "epoch [5/5], loss:0.1394\n",
      "epoch [1/5], loss:0.1484\n",
      "epoch [2/5], loss:0.0859\n",
      "epoch [3/5], loss:0.2962\n",
      "epoch [4/5], loss:0.0654\n",
      "epoch [5/5], loss:0.0674\n",
      "epoch [1/5], loss:0.1895\n",
      "epoch [2/5], loss:0.2394\n",
      "epoch [3/5], loss:0.1649\n",
      "epoch [4/5], loss:0.1073\n",
      "epoch [5/5], loss:0.0942\n",
      "epoch [1/5], loss:0.1944\n",
      "epoch [2/5], loss:0.1535\n",
      "epoch [3/5], loss:0.1567\n",
      "epoch [4/5], loss:0.1044\n",
      "epoch [5/5], loss:0.0336\n",
      "epoch [1/5], loss:0.1533\n",
      "epoch [2/5], loss:0.0638\n",
      "epoch [3/5], loss:0.0567\n",
      "epoch [4/5], loss:0.1290\n",
      "epoch [5/5], loss:0.0648\n",
      "epoch [1/5], loss:0.2145\n",
      "epoch [2/5], loss:0.1199\n",
      "epoch [3/5], loss:0.1040\n",
      "epoch [4/5], loss:0.1234\n",
      "epoch [5/5], loss:0.1212\n",
      "epoch [1/5], loss:0.0796\n",
      "epoch [2/5], loss:0.0931\n",
      "epoch [3/5], loss:0.0903\n",
      "epoch [4/5], loss:0.1052\n",
      "epoch [5/5], loss:0.1753\n",
      "epoch [1/5], loss:0.1169\n",
      "epoch [2/5], loss:0.0836\n",
      "epoch [3/5], loss:0.0886\n",
      "epoch [4/5], loss:0.0809\n",
      "epoch [5/5], loss:0.0715\n",
      "epoch [1/5], loss:0.0278\n",
      "epoch [2/5], loss:0.0804\n",
      "epoch [3/5], loss:0.0161\n",
      "epoch [4/5], loss:0.0835\n",
      "epoch [5/5], loss:0.0258\n",
      "epoch [1/5], loss:0.1300\n",
      "epoch [2/5], loss:0.0484\n",
      "epoch [3/5], loss:0.0504\n",
      "epoch [4/5], loss:0.1606\n",
      "epoch [5/5], loss:0.0515\n",
      "epoch [1/5], loss:0.1422\n",
      "epoch [2/5], loss:0.0933\n",
      "epoch [3/5], loss:0.0834\n",
      "epoch [4/5], loss:0.0680\n",
      "epoch [5/5], loss:0.1668\n",
      "epoch [1/5], loss:0.1303\n",
      "epoch [2/5], loss:0.1379\n",
      "epoch [3/5], loss:0.1206\n",
      "epoch [4/5], loss:0.1031\n",
      "epoch [5/5], loss:0.1071\n",
      "epoch [1/5], loss:0.0743\n",
      "epoch [2/5], loss:0.1171\n",
      "epoch [3/5], loss:0.0645\n",
      "epoch [4/5], loss:0.0357\n",
      "epoch [5/5], loss:0.0194\n",
      "epoch [1/5], loss:0.0902\n",
      "epoch [2/5], loss:0.0740\n",
      "epoch [3/5], loss:0.0754\n",
      "epoch [4/5], loss:0.0729\n",
      "epoch [5/5], loss:0.0848\n",
      "epoch [1/5], loss:0.1434\n",
      "epoch [2/5], loss:0.1405\n",
      "epoch [3/5], loss:0.0863\n",
      "epoch [4/5], loss:0.0777\n",
      "epoch [5/5], loss:0.0454\n",
      "epoch [1/5], loss:0.1539\n",
      "epoch [2/5], loss:0.1198\n",
      "epoch [3/5], loss:0.0862\n",
      "epoch [4/5], loss:0.0545\n",
      "epoch [5/5], loss:0.0617\n",
      "epoch [1/5], loss:0.0542\n",
      "epoch [2/5], loss:0.0242\n",
      "epoch [3/5], loss:0.0940\n",
      "epoch [4/5], loss:0.2654\n",
      "epoch [5/5], loss:0.0442\n",
      "epoch [1/5], loss:0.0506\n",
      "epoch [2/5], loss:0.0461\n",
      "epoch [3/5], loss:0.0068\n",
      "epoch [4/5], loss:0.0364\n",
      "epoch [5/5], loss:0.0071\n",
      "epoch [1/5], loss:0.0746\n",
      "epoch [2/5], loss:0.0527\n",
      "epoch [3/5], loss:0.0332\n",
      "epoch [4/5], loss:0.0332\n",
      "epoch [5/5], loss:0.0442\n",
      "epoch [1/5], loss:0.0736\n",
      "epoch [2/5], loss:0.1275\n",
      "epoch [3/5], loss:0.0733\n",
      "epoch [4/5], loss:0.1072\n",
      "epoch [5/5], loss:0.0993\n",
      "epoch [1/5], loss:0.0891\n",
      "epoch [2/5], loss:0.0557\n",
      "epoch [3/5], loss:0.1047\n",
      "epoch [4/5], loss:0.0650\n",
      "epoch [5/5], loss:0.0632\n",
      "epoch [1/5], loss:0.0688\n",
      "epoch [2/5], loss:0.0231\n",
      "epoch [3/5], loss:0.0346\n",
      "epoch [4/5], loss:0.0283\n",
      "epoch [5/5], loss:0.0431\n",
      "epoch [1/5], loss:0.0745\n",
      "epoch [2/5], loss:0.0474\n",
      "epoch [3/5], loss:0.0677\n",
      "epoch [4/5], loss:0.0462\n",
      "epoch [5/5], loss:0.0382\n",
      "epoch [1/5], loss:0.1039\n",
      "epoch [2/5], loss:0.0649\n",
      "epoch [3/5], loss:0.0680\n",
      "epoch [4/5], loss:0.1625\n",
      "epoch [5/5], loss:0.0682\n",
      "epoch [1/5], loss:0.0802\n",
      "epoch [2/5], loss:0.0985\n",
      "epoch [3/5], loss:0.0860\n",
      "epoch [4/5], loss:0.0678\n",
      "epoch [5/5], loss:0.0624\n",
      "epoch [1/5], loss:0.1430\n",
      "epoch [2/5], loss:0.0118\n",
      "epoch [3/5], loss:0.0122\n",
      "epoch [4/5], loss:0.0725\n",
      "epoch [5/5], loss:0.0128\n",
      "epoch [1/5], loss:0.1375\n",
      "epoch [2/5], loss:0.0684\n",
      "epoch [3/5], loss:0.0707\n",
      "epoch [4/5], loss:0.0456\n",
      "epoch [5/5], loss:0.0727\n",
      "epoch [1/5], loss:0.0673\n",
      "epoch [2/5], loss:0.0074\n",
      "epoch [3/5], loss:0.0527\n",
      "epoch [4/5], loss:0.0426\n",
      "epoch [5/5], loss:0.0634\n",
      "epoch [1/5], loss:0.0837\n",
      "epoch [2/5], loss:0.0606\n",
      "epoch [3/5], loss:0.0830\n",
      "epoch [4/5], loss:0.0523\n",
      "epoch [5/5], loss:0.0378\n",
      "epoch [1/5], loss:0.1063\n",
      "epoch [2/5], loss:0.0969\n",
      "epoch [3/5], loss:0.0756\n",
      "epoch [4/5], loss:0.0713\n",
      "epoch [5/5], loss:0.0832\n",
      "epoch [1/5], loss:0.0958\n",
      "epoch [2/5], loss:0.1899\n",
      "epoch [3/5], loss:0.0673\n",
      "epoch [4/5], loss:0.0068\n",
      "epoch [5/5], loss:0.0427\n",
      "epoch [1/5], loss:0.0694\n",
      "epoch [2/5], loss:0.0766\n",
      "epoch [3/5], loss:0.0475\n",
      "epoch [4/5], loss:0.0455\n",
      "epoch [5/5], loss:0.0453\n",
      "epoch [1/5], loss:0.2748\n",
      "epoch [2/5], loss:0.0832\n",
      "epoch [3/5], loss:0.0552\n",
      "epoch [4/5], loss:0.0594\n",
      "epoch [5/5], loss:0.0476\n",
      "epoch [1/5], loss:0.1042\n",
      "epoch [2/5], loss:0.0738\n",
      "epoch [3/5], loss:0.0754\n",
      "epoch [4/5], loss:0.0507\n",
      "epoch [5/5], loss:0.0374\n",
      "epoch [1/5], loss:0.0672\n",
      "epoch [2/5], loss:0.0465\n",
      "epoch [3/5], loss:0.0250\n",
      "epoch [4/5], loss:0.0143\n",
      "epoch [5/5], loss:0.0158\n",
      "epoch [1/5], loss:0.0433\n",
      "epoch [2/5], loss:0.0562\n",
      "epoch [3/5], loss:0.0429\n",
      "epoch [4/5], loss:0.0286\n",
      "epoch [5/5], loss:0.0394\n",
      "epoch [1/5], loss:0.0289\n",
      "epoch [2/5], loss:0.0418\n",
      "epoch [3/5], loss:0.0637\n",
      "epoch [4/5], loss:0.0502\n",
      "epoch [5/5], loss:0.0060\n",
      "epoch [1/5], loss:0.0687\n",
      "epoch [2/5], loss:0.0791\n",
      "epoch [3/5], loss:0.0922\n",
      "epoch [4/5], loss:0.0678\n",
      "epoch [5/5], loss:0.0524\n",
      "epoch [1/5], loss:0.0858\n",
      "epoch [2/5], loss:0.0470\n",
      "epoch [3/5], loss:0.1360\n",
      "epoch [4/5], loss:0.0528\n",
      "epoch [5/5], loss:0.0414\n",
      "epoch [1/5], loss:0.0681\n",
      "epoch [2/5], loss:0.0542\n",
      "epoch [3/5], loss:0.0525\n",
      "epoch [4/5], loss:0.0556\n",
      "epoch [5/5], loss:0.0562\n",
      "epoch [1/5], loss:0.0835\n",
      "epoch [2/5], loss:0.0726\n",
      "epoch [3/5], loss:0.0399\n",
      "epoch [4/5], loss:0.0659\n",
      "epoch [5/5], loss:0.0483\n",
      "epoch [1/5], loss:0.1433\n",
      "epoch [2/5], loss:0.1524\n",
      "epoch [3/5], loss:0.1555\n",
      "epoch [4/5], loss:0.1734\n",
      "epoch [5/5], loss:0.1250\n",
      "epoch [1/5], loss:0.1416\n",
      "epoch [2/5], loss:0.1022\n",
      "epoch [3/5], loss:0.0955\n",
      "epoch [4/5], loss:0.0815\n",
      "epoch [5/5], loss:0.0724\n",
      "epoch [1/5], loss:0.0664\n",
      "epoch [2/5], loss:0.1046\n",
      "epoch [3/5], loss:0.0719\n",
      "epoch [4/5], loss:0.0539\n",
      "epoch [5/5], loss:0.0606\n",
      "epoch [1/5], loss:0.1849\n",
      "epoch [2/5], loss:0.1487\n",
      "epoch [3/5], loss:0.1143\n",
      "epoch [4/5], loss:0.1432\n",
      "epoch [5/5], loss:0.0815\n",
      "epoch [1/5], loss:0.0854\n",
      "epoch [2/5], loss:0.0622\n",
      "epoch [3/5], loss:0.0622\n",
      "epoch [4/5], loss:0.0565\n",
      "epoch [5/5], loss:0.0373\n",
      "epoch [1/5], loss:0.0946\n",
      "epoch [2/5], loss:0.1303\n",
      "epoch [3/5], loss:0.0737\n",
      "epoch [4/5], loss:0.0579\n",
      "epoch [5/5], loss:0.0616\n",
      "epoch [1/5], loss:0.0995\n",
      "epoch [2/5], loss:0.0727\n",
      "epoch [3/5], loss:0.0790\n",
      "epoch [4/5], loss:0.0782\n",
      "epoch [5/5], loss:0.0828\n",
      "epoch [1/5], loss:0.1157\n",
      "epoch [2/5], loss:0.0739\n",
      "epoch [3/5], loss:0.0672\n",
      "epoch [4/5], loss:0.0592\n",
      "epoch [5/5], loss:0.0933\n",
      "epoch [1/5], loss:0.1337\n",
      "epoch [2/5], loss:0.1198\n",
      "epoch [3/5], loss:0.0540\n",
      "epoch [4/5], loss:0.0456\n",
      "epoch [5/5], loss:0.0614\n",
      "epoch [1/5], loss:0.0922\n",
      "epoch [2/5], loss:0.0824\n",
      "epoch [3/5], loss:0.0671\n",
      "epoch [4/5], loss:0.0535\n",
      "epoch [5/5], loss:0.0352\n",
      "epoch [1/5], loss:0.1975\n",
      "epoch [2/5], loss:0.1278\n",
      "epoch [3/5], loss:0.0839\n",
      "epoch [4/5], loss:0.0855\n",
      "epoch [5/5], loss:0.0534\n",
      "epoch [1/5], loss:0.1433\n",
      "epoch [2/5], loss:0.0471\n",
      "epoch [3/5], loss:0.0539\n",
      "epoch [4/5], loss:0.0382\n",
      "epoch [5/5], loss:0.1060\n",
      "epoch [1/5], loss:0.0595\n",
      "epoch [2/5], loss:0.0584\n",
      "epoch [3/5], loss:0.0525\n",
      "epoch [4/5], loss:0.0818\n",
      "epoch [5/5], loss:0.0338\n",
      "epoch [1/5], loss:0.0785\n",
      "epoch [2/5], loss:0.0725\n",
      "epoch [3/5], loss:0.0580\n",
      "epoch [4/5], loss:0.0369\n",
      "epoch [5/5], loss:0.0467\n",
      "epoch [1/5], loss:0.0676\n",
      "epoch [2/5], loss:0.0267\n",
      "epoch [3/5], loss:0.0618\n",
      "epoch [4/5], loss:0.0298\n",
      "epoch [5/5], loss:0.0430\n",
      "epoch [1/5], loss:0.2376\n",
      "epoch [2/5], loss:0.1017\n",
      "epoch [3/5], loss:0.2259\n",
      "epoch [4/5], loss:0.0950\n",
      "epoch [5/5], loss:0.0936\n",
      "epoch [1/5], loss:0.2565\n",
      "epoch [2/5], loss:0.1077\n",
      "epoch [3/5], loss:0.1071\n",
      "epoch [4/5], loss:0.0778\n",
      "epoch [5/5], loss:0.1633\n",
      "epoch [1/5], loss:0.1506\n",
      "epoch [2/5], loss:0.1127\n",
      "epoch [3/5], loss:0.1250\n",
      "epoch [4/5], loss:0.0835\n",
      "epoch [5/5], loss:0.1099\n",
      "epoch [1/5], loss:0.1276\n",
      "epoch [2/5], loss:0.1743\n",
      "epoch [3/5], loss:0.0749\n",
      "epoch [4/5], loss:0.0611\n",
      "epoch [5/5], loss:0.0667\n",
      "epoch [1/5], loss:0.0844\n",
      "epoch [2/5], loss:0.0814\n",
      "epoch [3/5], loss:0.0864\n",
      "epoch [4/5], loss:0.1006\n",
      "epoch [5/5], loss:0.0642\n",
      "epoch [1/5], loss:0.1735\n",
      "epoch [2/5], loss:0.1273\n",
      "epoch [3/5], loss:0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/5], loss:0.0742\n",
      "epoch [5/5], loss:0.0792\n",
      "epoch [1/5], loss:0.0746\n",
      "epoch [2/5], loss:0.1124\n",
      "epoch [3/5], loss:0.0691\n",
      "epoch [4/5], loss:0.0743\n",
      "epoch [5/5], loss:0.0524\n",
      "epoch [1/5], loss:0.0743\n",
      "epoch [2/5], loss:0.0573\n",
      "epoch [3/5], loss:0.0769\n",
      "epoch [4/5], loss:0.0554\n",
      "epoch [5/5], loss:0.0622\n",
      "epoch [1/5], loss:0.1391\n",
      "epoch [2/5], loss:0.0982\n",
      "epoch [3/5], loss:0.0863\n",
      "epoch [4/5], loss:0.0865\n",
      "epoch [5/5], loss:0.0495\n",
      "epoch [1/5], loss:0.1301\n",
      "epoch [2/5], loss:0.0657\n",
      "epoch [3/5], loss:0.0759\n",
      "epoch [4/5], loss:0.0544\n",
      "epoch [5/5], loss:0.0433\n"
     ]
    }
   ],
   "source": [
    "trainSpectra = []\n",
    "i = 0\n",
    "for key in TrainingKeys:\n",
    "    trainSpectra.append(torch.empty_like(TrainingSamples[key].spectra))\n",
    "    for j in range(TrainingSamples[key].spectra.size()[0]):\n",
    "        trainSpectra[i][j] = TrainingSamples[key].spectrum + TrainingSamples[key].spectra[j]\n",
    "    i += 1\n",
    "\n",
    "vb = TempVB()\n",
    "for i in range(70):\n",
    "    vb.crfAi.train(trainSpectra[i], epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "directed-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "borders = [0, 1, 2,\n",
    "           31, 32, 32,\n",
    "           40, 45, 50,\n",
    "           75, 76, 76,\n",
    "           82, 83, 86,\n",
    "           128, 129, 130\n",
    "          ]\n",
    "phonemes = [\"A\", \"N\", \"A\", \"T\", \"A\"]\n",
    "#offsets = [0, 5, 1, 1, 1]\n",
    "offsets = [0, 20, 20, 0, 13]\n",
    "\n",
    "sequence = VocalSequence(0, 400, vb, borders, phonemes, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "velvet-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "secret-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2e728ef70>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.spectrum[29].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "strange-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b2d3900d30>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.synth.returnSignal.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
