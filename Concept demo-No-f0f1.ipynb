{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jokla\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.Pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float)\n",
    "        self.voicedExcitation = torch.tensor([], dtype = float)\n",
    "        self.VoicedExcitations = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.Pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "        \n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 10, preIterations = 2):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        \n",
    "        workingSpectra = torch.log(signalsAbs)\n",
    "        \n",
    "        workingSpectra = torch.max(workingSpectra, torch.tensor([-100]))\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        \n",
    "        for j in range(preIterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.VoicedExcitations = torch.zeros_like(signals)\n",
    "        for i in range(signals.size()[0]):\n",
    "            for j in range(signals.size()[1]):\n",
    "                if torch.log(signalsAbs[i][j]) > self.spectra[i][j]:\n",
    "                    self.VoicedExcitations[i][j] = signals[i][j]\n",
    "                \n",
    "        for j in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "        \n",
    "    def CalculateExcitation(self, filterWidth = 10):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / (torch.exp(self.spectrum) + torch.exp(self.spectra[i]))\n",
    "            self.VoicedExcitations[i] = self.VoicedExcitations[i] / (torch.exp(self.spectrum) + torch.exp(self.spectra[i]))\n",
    "        \n",
    "        VoicedExcitations = torch.transpose(self.VoicedExcitations, 0, 1)\n",
    "            \n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        self.voicedExcitation = torch.istft(VoicedExcitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        \n",
    "        self.excitation = self.excitation - self.voicedExcitation\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expired-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(RelLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, targets):    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        differences = torch.abs(inputs - targets)\n",
    "        sums = torch.abs(inputs + targets)\n",
    "        out = (differences / sums).sum() / inputs.size()[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configured-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi_train(nn.Module):\n",
    "    def __init__(self, learningRate=1e-4):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Linear(3843, 3843)\n",
    "        self.ReLu1 = nn.PReLU()\n",
    "        self.layer2 = torch.nn.Linear(3843, 5763)\n",
    "        self.ReLu2 = nn.PReLU()\n",
    "        self.layer3 = torch.nn.Linear(5763, 3842)\n",
    "        self.ReLu3 = nn.PReLU()\n",
    "        self.layer4 = torch.nn.Linear(3842, 1921)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #self.criterion = RelLoss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.tensor([factor])\n",
    "        x = torch.cat((spectrum1, spectrum2, fac), dim = 0)\n",
    "        x = x.float()#.unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.ReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                indexList = numpy.arange(0, data.size()[0], 1)\n",
    "                numpy.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSegment:\n",
    "    def __init__(self, start1, start2, start3, end1, end2, end3, startCap, endCap, phonemeKey, vb, offset, repetititionSpacing, pitch, steadiness):\n",
    "        self.start1 = start1\n",
    "        self.start2 = start2\n",
    "        self.start3 = start3\n",
    "        self.end1 = end1\n",
    "        self.end2 = end2\n",
    "        self.end3 = end3\n",
    "        self.startCap = startCap\n",
    "        self.endCap = endCap\n",
    "        self.phonemeKey = phonemeKey\n",
    "        self.vb = vb\n",
    "        self.offset = offset\n",
    "        self.repetititionSpacing = repetititionSpacing\n",
    "        self.pitch = pitch\n",
    "        self.steadiness = steadiness\n",
    "    def getSpectrum(self):\n",
    "        if self.startCap:\n",
    "            windowStart = self.offset\n",
    "        else:\n",
    "            windowStart = self.start3 - self.start1 + self.offset\n",
    "        if self.endCap:\n",
    "            windowEnd = self.end3 - self.start1 + self.offset\n",
    "        else:\n",
    "            windowEnd = self.end1 - self.start1 + self.offset\n",
    "        spectrum =  self.vb.phonemeDict[self.phonemeKey].spectrum[windowStart:windowEnd]#implement looping\n",
    "        spectra =  self.vb.phonemeDict[self.phonemeKey].spectrum[windowStart:windowEnd]\n",
    "        return torch.exp(spectrum) +  torch.pow(1 - self.steadiness, 2) * torch.exp(spectra)\n",
    "    \n",
    "    def getExcitation(self):\n",
    "        premul = self.vb.phonemeDict[phonemeKey].excitation.size()[0] * self.vb.sampleRate / 75 / (self.end3 - self.start1)\n",
    "        #edge cases\n",
    "        windowStart = int((self.start2 - self.start1 + self.offset) * premul)\n",
    "        windowEnd = int(self.end2 - self.start1 + self.offset * premul)\n",
    "        excitation = self.vb.phonemeDict[phonemeKey].excitation[windowStart:windowEnd]\n",
    "        transform = torchaudio.transforms.TimeStretch(hop_length = self.vb.sampleRate / 75,\n",
    "                                                      n_freq = self.vb.sampleRate / 25, \n",
    "                                                      fixed_rate: = 1. / premul)\n",
    "        return transform(excitation)\n",
    "    def getVoicedExcitation(self):\n",
    "        nativePitch = self.vb.phonemeDict[self.phonemeKey].pitch\n",
    "        #nativePitch = self.vb.phonemeDict[self.phonemeKey].pitches[...]\n",
    "        #pitch = nativePitch + self.vb.phonemeDict[phonemeKey].pitches...\n",
    "        transform = torchaudio.transforms.Resample(orig_freq = self.vb.sampleRate,\n",
    "                                                   new_freq = self.vb.sampleRate * self.nativePitch / self.pitch,\n",
    "                                                   resampling_method = 'sinc_interpolation',\n",
    "                                                   lowpass_filter_width = 6,\n",
    "                                                   rolloff = 0.99,\n",
    "                                                   beta = None)\n",
    "        #resample segments\n",
    "        #individual fourier transform\n",
    "        #istft\n",
    "        #windowing adaptive to borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSequence:\n",
    "    def __init__(self, start, end, vb, borders, phonemes, offsets):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.vb = vb\n",
    "        self.segments = []\n",
    "        if len(phonemes)== 1:#rewrite border system to use tensor, implement pitch and steadiness\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, True, phonemes[0], vb, offsets[0], None, 385, 0))\n",
    "        else:\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, False, phonemes[0], vb, offsets[0], None, 385, 0))\n",
    "            for i in range(1, len(phonemes)-1):\n",
    "                self.segments.append(VocalSegment(borders[3*i], borders[3*i+1], borders[3*i+2], borders[3*i+3], borders[3*i+4], borders[3*i+5],\n",
    "                                                  False, False, phonemes[i], vb, offsets[i], None, 385, 0))\n",
    "            endpoint = len(phonemes)-1\n",
    "            self.segments.append(VocalSegment(borders[3*endpoint], borders[3*endpoint+1], borders[3*endpoint+2], borders[3*endpoint+3], borders[3*endpoint+4], borders[3*endpoint+5],\n",
    "                                             False, True, phonemes[0], vb, offsets[0], None, 385, 0))\n",
    "\n",
    "        self.audio = torch.zeros((self.end - self.start) * self.vb.sampleRate / 75)\n",
    "        self.requiresUpdate = np.ones(len(phonemes))\n",
    "        self.update()\n",
    "    def update(self):\n",
    "        for i in range(requiresUpdate.size):\n",
    "            if requiresUpdate[i] == 1:\n",
    "                segment = self.segment[i]\n",
    "                spectrum = torch.zeros(segment.end3 - segment.start1, self.vb.sampleRate / 25)\n",
    "                if self.startCap:\n",
    "                    windowStart = self.offset\n",
    "                else:\n",
    "                    windowStart = self.start3 - self.start1 + self.offset\n",
    "                    previousSpectrum = self.segments[i-1].getSpectrum()[-1]\n",
    "                if self.endCap:\n",
    "                    windowEnd = self.end3 - self.start1 + self.offset\n",
    "                else:\n",
    "                    windowEnd = self.end1 - self.start1 + self.offset\n",
    "                    nextSpectrum = self.segments[i+1].getSpectrum()[0]\n",
    "                spectrum[windowStart:windowEnd] = segment.getSpectrum()\n",
    "                \n",
    "                voicedExcitation[windowStart:windowEnd] = segment.getVoicedExcitation()\n",
    "                #new windows\n",
    "                excitation[windowStart:windowEnd] = segment.getExcitation()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempVB:\n",
    "    def __init__(self):\n",
    "        self.sampleRate = 48000\n",
    "        self.phonemeDict = dict([])\n",
    "        phonemeKeys = [\"A\", \"E\", \"I\", \"O\", \"U\", \"G\", \"K\", \"N\", \"S\", \"T\"]\n",
    "        for key in phonemeKeys:\n",
    "            phonemeDict[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "            phonemeDict[key].CalculatePitch(385.)\n",
    "            phonemeDict[key].CalculateSpectra(iterations = 15)\n",
    "            phonemeDict[key].CalculateExcitation()\n",
    "        self.crfAi = specCrfAi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voicebank:\n",
    "    def __init__(self, vbKey):\n",
    "        self.phonemeDict = dict()\n",
    "        loaded_weights = 0#(vbKey)\n",
    "        self.crfAi = 0#SpecCrfAi(loaded_weights)\n",
    "        #load additional parameters\n",
    "        self.sampleRate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, SampleRate):\n",
    "        self.sampleRate = SampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def Synthesize(self, steadiness, Spectrum, Spectra, Excitation, VoicedExcitation):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        self.returnSignal = torch.stft(Excitation + VoicedExcitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        for i in range(Spectra.size()[0]):\n",
    "            self.returnSignal[i] = self.returnSignal[i] * (torch.exp(Spectrum)[i] +  math.pow(1 - steadiness, 2) * torch.exp(Spectra)[i])\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided=True, )\n",
    "        del Window\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal.detach(), 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "latin-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSamples = dict([])\n",
    "TrainingKeys = [\"A_E\", \"A_G\", \"A_I\", \"A_K\", \"A_N\", \"A_O\", \"A_S\", \"A_T\", \"A_U\",\n",
    "                   \"E_A\", \"E_G\", \"E_I\", \"E_K\", \"E_N\", \"E_O\", \"E_S\", \"E_T\", \"E_U\",\n",
    "                   \"I_A\", \"I_E\", \"I_G\", \"I_K\", \"I_N\", \"I_O\", \"I_S\", \"I_T\", \"I_U\",\n",
    "                   \"O_A\", \"O_E\", \"O_G\", \"O_I\", \"O_K\", \"O_N\", \"O_S\", \"O_T\", \"O_U\",\n",
    "                   \"U_A\", \"U_E\", \"U_G\", \"U_I\", \"U_K\", \"U_N\", \"U_O\", \"U_S\", \"U_T\",\n",
    "                   \"G_A\", \"G_E\", \"G_I\", \"G_O\", \"G_U\",\n",
    "                   \"K_A\", \"K_E\", \"K_I\", \"K_O\", \"K_U\",\n",
    "                   \"N_A\", \"N_E\", \"N_I\", \"N_O\", \"N_U\",\n",
    "                   \"S_A\", \"S_E\", \"S_I\", \"S_O\", \"S_U\",\n",
    "                   \"T_A\", \"T_E\", \"T_I\", \"T_O\", \"T_U\"\n",
    "                  ]\n",
    "\n",
    "for key in TrainingKeys:\n",
    "    TrainingSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    TrainingSamples[key].CalculatePitch(252.)\n",
    "    TrainingSamples[key].CalculateSpectra(iterations = 25)\n",
    "    TrainingSamples[key].CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "former-economics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/2], loss:1.3274\n",
      "epoch [2/2], loss:0.9209\n",
      "epoch [1/2], loss:1.4807\n",
      "epoch [2/2], loss:1.3161\n",
      "epoch [1/2], loss:0.7029\n",
      "epoch [2/2], loss:0.6343\n",
      "epoch [1/2], loss:3.0549\n",
      "epoch [2/2], loss:1.7203\n",
      "epoch [1/2], loss:1.9917\n",
      "epoch [2/2], loss:1.9700\n",
      "epoch [1/2], loss:0.4737\n",
      "epoch [2/2], loss:0.9784\n",
      "epoch [1/2], loss:0.5716\n",
      "epoch [2/2], loss:0.5416\n",
      "epoch [1/2], loss:1.0779\n",
      "epoch [2/2], loss:1.5961\n",
      "epoch [1/2], loss:0.5671\n",
      "epoch [2/2], loss:0.4382\n",
      "epoch [1/2], loss:0.4413\n",
      "epoch [2/2], loss:0.5281\n",
      "epoch [1/2], loss:0.7318\n",
      "epoch [2/2], loss:0.6468\n",
      "epoch [1/2], loss:0.9807\n",
      "epoch [2/2], loss:0.3944\n",
      "epoch [1/2], loss:0.9413\n",
      "epoch [2/2], loss:1.2615\n",
      "epoch [1/2], loss:0.5533\n",
      "epoch [2/2], loss:0.5504\n",
      "epoch [1/2], loss:0.6505\n",
      "epoch [2/2], loss:0.4894\n",
      "epoch [1/2], loss:0.4724\n",
      "epoch [2/2], loss:0.5866\n",
      "epoch [1/2], loss:1.0423\n",
      "epoch [2/2], loss:0.5020\n",
      "epoch [1/2], loss:0.5258\n",
      "epoch [2/2], loss:0.3783\n",
      "epoch [1/2], loss:0.5291\n",
      "epoch [2/2], loss:0.4228\n",
      "epoch [1/2], loss:1.2141\n",
      "epoch [2/2], loss:0.6722\n",
      "epoch [1/2], loss:2.3296\n",
      "epoch [2/2], loss:1.2671\n",
      "epoch [1/2], loss:0.7722\n",
      "epoch [2/2], loss:0.8321\n",
      "epoch [1/2], loss:0.6628\n",
      "epoch [2/2], loss:0.7129\n",
      "epoch [1/2], loss:0.6302\n",
      "epoch [2/2], loss:0.4056\n",
      "epoch [1/2], loss:0.5559\n",
      "epoch [2/2], loss:0.4240\n",
      "epoch [1/2], loss:0.4352\n",
      "epoch [2/2], loss:0.5019\n",
      "epoch [1/2], loss:0.5422\n",
      "epoch [2/2], loss:0.4198\n",
      "epoch [1/2], loss:0.4424\n",
      "epoch [2/2], loss:0.3230\n",
      "epoch [1/2], loss:0.3830\n",
      "epoch [2/2], loss:0.3540\n",
      "epoch [1/2], loss:0.7005\n",
      "epoch [2/2], loss:0.6732\n",
      "epoch [1/2], loss:0.4835\n",
      "epoch [2/2], loss:0.3094\n",
      "epoch [1/2], loss:0.5397\n",
      "epoch [2/2], loss:0.4133\n",
      "epoch [1/2], loss:0.5208\n",
      "epoch [2/2], loss:0.3399\n",
      "epoch [1/2], loss:0.4192\n",
      "epoch [2/2], loss:0.5566\n",
      "epoch [1/2], loss:0.9456\n",
      "epoch [2/2], loss:0.7724\n",
      "epoch [1/2], loss:0.3189\n",
      "epoch [2/2], loss:0.2767\n",
      "epoch [1/2], loss:0.3631\n",
      "epoch [2/2], loss:0.3335\n",
      "epoch [1/2], loss:0.3181\n",
      "epoch [2/2], loss:0.4291\n",
      "epoch [1/2], loss:0.8620\n",
      "epoch [2/2], loss:1.2726\n",
      "epoch [1/2], loss:0.9217\n",
      "epoch [2/2], loss:0.4669\n",
      "epoch [1/2], loss:1.2397\n",
      "epoch [2/2], loss:0.5432\n",
      "epoch [1/2], loss:0.4249\n",
      "epoch [2/2], loss:0.5540\n",
      "epoch [1/2], loss:0.3982\n",
      "epoch [2/2], loss:0.4621\n",
      "epoch [1/2], loss:0.6929\n",
      "epoch [2/2], loss:0.4066\n",
      "epoch [1/2], loss:0.4242\n",
      "epoch [2/2], loss:0.8200\n",
      "epoch [1/2], loss:0.5244\n",
      "epoch [2/2], loss:0.7394\n",
      "epoch [1/2], loss:0.3801\n",
      "epoch [2/2], loss:0.4668\n",
      "epoch [1/2], loss:0.2931\n",
      "epoch [2/2], loss:0.5315\n",
      "epoch [1/2], loss:0.5076\n",
      "epoch [2/2], loss:0.3546\n",
      "epoch [1/2], loss:0.3627\n",
      "epoch [2/2], loss:0.3983\n",
      "epoch [1/2], loss:0.3305\n",
      "epoch [2/2], loss:0.5118\n",
      "epoch [1/2], loss:0.4678\n",
      "epoch [2/2], loss:0.4107\n",
      "epoch [1/2], loss:0.2897\n",
      "epoch [2/2], loss:0.3232\n",
      "epoch [1/2], loss:0.4435\n",
      "epoch [2/2], loss:0.5885\n",
      "epoch [1/2], loss:0.4050\n",
      "epoch [2/2], loss:0.4737\n",
      "epoch [1/2], loss:0.4121\n",
      "epoch [2/2], loss:0.4315\n",
      "epoch [1/2], loss:0.6085\n",
      "epoch [2/2], loss:0.3373\n",
      "epoch [1/2], loss:1.0404\n",
      "epoch [2/2], loss:0.2430\n",
      "epoch [1/2], loss:0.3543\n",
      "epoch [2/2], loss:0.5143\n",
      "epoch [1/2], loss:0.2743\n",
      "epoch [2/2], loss:0.3163\n",
      "epoch [1/2], loss:0.5220\n",
      "epoch [2/2], loss:0.7168\n",
      "epoch [1/2], loss:0.5544\n",
      "epoch [2/2], loss:0.6788\n",
      "epoch [1/2], loss:0.4685\n",
      "epoch [2/2], loss:0.8185\n",
      "epoch [1/2], loss:0.8354\n",
      "epoch [2/2], loss:0.5955\n",
      "epoch [1/2], loss:0.3982\n",
      "epoch [2/2], loss:1.0216\n",
      "epoch [1/2], loss:0.3261\n",
      "epoch [2/2], loss:0.8084\n",
      "epoch [1/2], loss:0.4092\n",
      "epoch [2/2], loss:0.9355\n",
      "epoch [1/2], loss:0.4482\n",
      "epoch [2/2], loss:0.2311\n",
      "epoch [1/2], loss:0.5427\n",
      "epoch [2/2], loss:0.3049\n",
      "epoch [1/2], loss:0.2663\n",
      "epoch [2/2], loss:0.3447\n"
     ]
    }
   ],
   "source": [
    "trainSpectra = []\n",
    "i = 0\n",
    "for key in TrainingKeys:\n",
    "    trainSpectra.append(torch.empty_like(TrainingSamples[key].spectra))\n",
    "    for j in range(TrainingSamples[key].spectra.size()[0]):\n",
    "        trainSpectra[i][j] = TrainingSamples[key].spectrum + TrainingSamples[key].spectra[j]\n",
    "    i += 1\n",
    "    \n",
    "specCrfAi = SpecCrfAi_train(learningRate=1e-4)\n",
    "for i in range(70):\n",
    "    specCrfAi.train(trainSpectra[i], epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "developmental-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testspectrum = torch.zeros(PhonemeSamples[\"A\"].spectrum.size()[0], 0)\n",
    "Testspectra = torch.zeros(PhonemeSamples[\"A\"].spectrum.size()[0], 0)\n",
    "Testexcitation = torch.tensor([])\n",
    "TestVoicedExcitation = torch.tensor([])\n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i].unsqueeze(1)), dim=1)\n",
    "for i in range(50 * 1280):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    TestVoicedExcitation = torch.cat((TestVoicedExcitation, PhonemeSamples[\"A\"].voicedExcitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(40):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"N\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"N\"].spectra[i + 0].unsqueeze(1)), dim=1)\n",
    "for i in range(0, 40 * 1280 + 0):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"N\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    TestVoicedExcitation = torch.cat((TestVoicedExcitation, PhonemeSamples[\"N\"].voicedExcitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i + 6].unsqueeze(1)), dim=1)\n",
    "for i in range(6, 50 * 1280 + 6):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    TestVoicedExcitation = torch.cat((TestVoicedExcitation, PhonemeSamples[\"A\"].voicedExcitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(12):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"T\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"T\"].spectra[i + 0].unsqueeze(1)), dim=1)\n",
    "for i in range(0, 12 * 1280 + 0):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"T\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    TestVoicedExcitation = torch.cat((TestVoicedExcitation, PhonemeSamples[\"T\"].voicedExcitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "for i in range(50):\n",
    "    Testspectrum = torch.cat((Testspectrum, PhonemeSamples[\"A\"].spectrum.unsqueeze(1)), dim=1)\n",
    "    Testspectra = torch.cat((Testspectra, PhonemeSamples[\"A\"].spectra[i + 6].unsqueeze(1)), dim=1)\n",
    "for i in range(6, 50 * 1280 + 6):\n",
    "    Testexcitation = torch.cat((Testexcitation, PhonemeSamples[\"A\"].excitation[i].unsqueeze(0)), dim=0)\n",
    "    TestVoicedExcitation = torch.cat((TestVoicedExcitation, PhonemeSamples[\"A\"].voicedExcitation[i].unsqueeze(0)), dim=0)\n",
    "    \n",
    "Testspectrum = torch.transpose(Testspectrum, 0, 1)\n",
    "Testspectra = torch.transpose(Testspectra, 0, 1)\n",
    "    \n",
    "for i in range(40, 60):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[39], Testspectrum[60], 0.05 * (i - 40))\n",
    "    \n",
    "for i in range(85, 95):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[84], Testspectrum[95], 0.1 * (i - 85))\n",
    "    \n",
    "for i in range(135, 145):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[134], Testspectrum[145], 0.1 * (i - 135))\n",
    "    \n",
    "for i in range(155, 165):\n",
    "    Testspectrum[i] = specCrfAi.processData(Testspectrum[154], Testspectrum[165], 0.1 * (i - 155))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flying-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = Synthesizer(PhonemeSamples[\"A\"].sampleRate)\n",
    "synthesizer.Synthesize(0., Testspectrum, Testspectra, Testexcitation, TestVoicedExcitation)\n",
    "synthesizer.save(\"Output_S2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blind-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PhonemeSamples[\"A\"].CalculateSpectra(iterations = 15, preIterations = 2)\n",
    "plt.plot(PhonemeSamples[\"A\"].spectrum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suburban-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14f893de3a0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.stft(PhonemeSamples[\"A\"].waveform, 1920, hop_length = 640, win_length = 1920, return_complex = True).abs().transpose(0, 1)[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "packed-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(specCrfAi.state_dict(), \"CrossfadeWeights.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-tiffany",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
