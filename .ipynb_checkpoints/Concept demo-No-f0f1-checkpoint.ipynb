{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jokla\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float)\n",
    "        self.voicedExcitation = torch.tensor([], dtype = float)\n",
    "        self.VoicedExcitations = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "        \n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 10, preIterations = 2):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        \n",
    "        workingSpectra = torch.sqrt(signalsAbs)\n",
    "        \n",
    "        workingSpectra = torch.max(workingSpectra, torch.tensor([-100]))\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        \n",
    "        for j in range(preIterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.VoicedExcitations = torch.zeros_like(signals)\n",
    "        for i in range(signals.size()[0]):\n",
    "            for j in range(signals.size()[1]):\n",
    "                if torch.sqrt(signalsAbs[i][j]) > self.spectra[i][j]:\n",
    "                    self.VoicedExcitations[i][j] = signals[i][j]\n",
    "                \n",
    "        for j in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        #return torch.log(signalsAbs)\n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "        \n",
    "    def CalculateExcitation(self, filterWidth = 10):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "            self.VoicedExcitations[i] = self.VoicedExcitations[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "        \n",
    "        VoicedExcitations = torch.transpose(self.VoicedExcitations, 0, 1)\n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        self.voicedExcitation = torch.istft(VoicedExcitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        \n",
    "        self.excitation = self.excitation - self.voicedExcitation\n",
    "        self.excitation = torch.stft(self.excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        \n",
    "        self.excitation = torch.transpose(self.excitation, 0, 1)\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expired-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(RelLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, targets):    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        differences = torch.abs(inputs - targets)\n",
    "        sums = torch.abs(inputs + targets)\n",
    "        out = (differences / sums).sum() / inputs.size()[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configured-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi(nn.Module):\n",
    "    def __init__(self, learningRate=1e-4):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Linear(3843, 3843)\n",
    "        self.ReLu1 = nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(3843, 5763)\n",
    "        self.ReLu2 = nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(5763, 3842)\n",
    "        self.ReLu3 = nn.ReLU()\n",
    "        self.layer4 = torch.nn.Linear(3842, 1921)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #self.criterion = RelLoss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.tensor([factor])\n",
    "        x = torch.cat((spectrum1, spectrum2, fac), dim = 0)\n",
    "        x = x.float()#.unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.ReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        output = torch.square(torch.squeeze(self(torch.sqrt(spectrum1), torch.sqrt(spectrum2), factor)))\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                indexList = np.arange(0, data.size()[0], 1)\n",
    "                np.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "black-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSegment:\n",
    "    def __init__(self, start1, start2, start3, end1, end2, end3, startCap, endCap, phonemeKey, vb, offset, repetititionSpacing, pitch, steadiness):\n",
    "        self.start1 = start1\n",
    "        self.start2 = start2\n",
    "        self.start3 = start3\n",
    "        self.end1 = end1\n",
    "        self.end2 = end2\n",
    "        self.end3 = end3\n",
    "        self.startCap = startCap\n",
    "        self.endCap = endCap\n",
    "        self.phonemeKey = phonemeKey\n",
    "        self.vb = vb\n",
    "        self.offset = offset\n",
    "        self.repetititionSpacing = repetititionSpacing\n",
    "        self.pitch = pitch\n",
    "        self.steadiness = steadiness\n",
    "        \n",
    "    def phaseShift(inputTensor, pitch, phase):\n",
    "        inputTensor = torch.transpose(inputTensor, 0, 1)\n",
    "        absolutes = inputTensor.abs()\n",
    "        phases = inputTensor.angle()\n",
    "        #2*math.pi\n",
    "        #freq.: 0, 75, 150, 225, 300, 375, 450, 525, 600, 675, ...\n",
    "        #phase shift multiplied by targetIndex / pitchIndex\n",
    "        \n",
    "    def loopSampler(inputTensor, repetititionSpacing, phaseAlign):\n",
    "        pass\n",
    "        \n",
    "    def getSpectrum(self):\n",
    "        if self.startCap:\n",
    "            windowStart = self.offset\n",
    "        else:\n",
    "            windowStart = self.start3 - self.start1 + self.offset\n",
    "        if self.endCap:\n",
    "            windowEnd = self.end3 - self.start1 + self.offset\n",
    "        else:\n",
    "            windowEnd = self.end1 - self.start1 + self.offset\n",
    "        spectrum =  self.vb.phonemeDict[self.phonemeKey].spectrum#implement looping\n",
    "        spectra =  self.vb.phonemeDict[self.phonemeKey].spectra[windowStart:windowEnd]\n",
    "        return torch.square(spectrum + (math.pow(1 - self.steadiness, 2) * spectra))\n",
    "    \n",
    "    def getExcitation(self):\n",
    "        BatchSize = int(self.vb.sampleRate / 75)\n",
    "        tripleBatchSize = int(self.vb.sampleRate / 25)\n",
    "        premul = self.vb.phonemeDict[self.phonemeKey].excitation.size()[0] / (self.end3 - self.start1 + 1)\n",
    "        #premul = 1\n",
    "        if self.startCap:\n",
    "            windowStart = 0#math.floor(self.offset)\n",
    "            length = -self.start1\n",
    "        else:\n",
    "            windowStart = math.floor((self.start2 - self.start1) * premul)# + self.offset)\n",
    "            length = -self.start2\n",
    "        if self.endCap:\n",
    "            windowEnd = math.ceil((self.end3 - self.start1) * premul)# + self.offset)\n",
    "            length += self.end3\n",
    "        else:\n",
    "            windowEnd = math.ceil((self.end2 - self.start1) * premul)# + self.offset)\n",
    "            length += self.end2\n",
    "        excitation = self.vb.phonemeDict[self.phonemeKey].excitation[windowStart:windowEnd]\n",
    "        excitation = torch.transpose(excitation, 0, 1)\n",
    "        transform = torchaudio.transforms.TimeStretch(hop_length = int(self.vb.sampleRate / 75),\n",
    "                                                      n_freq = int(self.vb.sampleRate / 25 / 2) + 1, \n",
    "                                                      fixed_rate = premul)\n",
    "        excitation = transform(torch.view_as_real(excitation))\n",
    "        excitation = torch.view_as_complex(excitation)\n",
    "        window = torch.hann_window(int(self.vb.sampleRate / 25))\n",
    "        excitation = torch.istft(excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = window, onesided = True, length = length*int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        return excitation[0:length*int(self.vb.sampleRate / 75)]\n",
    "    \n",
    "    def getVoicedExcitation(self):\n",
    "        nativePitch = self.vb.phonemeDict[self.phonemeKey].pitch\n",
    "        #nativePitch = self.vb.phonemeDict[self.phonemeKey].pitches[...]\n",
    "        #pitch = nativePitch + self.vb.phonemeDict[phonemeKey].pitches...\n",
    "        premul = self.pitch / nativePitch * self.vb.sampleRate / 75\n",
    "        windowStart = math.floor(self.offset * self.vb.sampleRate / 75)\n",
    "        windowEnd = math.ceil((self.end3 - self.start1) * premul + (self.offset * self.vb.sampleRate / 75))\n",
    "        voicedExcitation = self.vb.phonemeDict[self.phonemeKey].voicedExcitation[windowStart:windowEnd]\n",
    "        transform = torchaudio.transforms.Resample(orig_freq = nativePitch,#self.pitch,\n",
    "                                                   new_freq = self.pitch,#nativePitch,\n",
    "                                                   resampling_method = 'sinc_interpolation')\n",
    "        voicedExcitation = transform(voicedExcitation)\n",
    "        if self.startCap == False:\n",
    "            slope = torch.linspace(0, 1, (self.start3 - self.start1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[0:(self.start3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        if self.endCap == False:\n",
    "            slope = torch.linspace(1, 0, (self.end3 - self.end1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[(self.end1 - self.start1) * int(self.vb.sampleRate / 75):(self.end3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        print(windowStart, windowEnd, self.start1, self.end3)\n",
    "        return voicedExcitation[0:(self.end3 - self.start1) * int(self.vb.sampleRate / 75)]\n",
    "        #resample segments\n",
    "        #individual fourier transform\n",
    "        #istft\n",
    "        #windowing adaptive to borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "emotional-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSequence:\n",
    "    def __init__(self, start, end, vb, borders, phonemes, offsets):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.vb = vb\n",
    "        self.synth = Synthesizer(self.vb.sampleRate)\n",
    "        \n",
    "        self.spectrum = torch.zeros((self.end - self.start, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "        self.excitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        self.voicedExcitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        self.segments = []\n",
    "        if len(phonemes)== 1:#rewrite border system to use tensor, implement pitch and steadiness\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, True, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "        else:\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, False, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "            for i in range(1, len(phonemes)-1):\n",
    "                self.segments.append(VocalSegment(borders[3*i], borders[3*i+1], borders[3*i+2], borders[3*i+3], borders[3*i+4], borders[3*i+5],\n",
    "                                                  False, False, phonemes[i], vb, offsets[i], None, 386, 0))\n",
    "            endpoint = len(phonemes)-1\n",
    "            self.segments.append(VocalSegment(borders[3*endpoint], borders[3*endpoint+1], borders[3*endpoint+2], borders[3*endpoint+3], borders[3*endpoint+4], borders[3*endpoint+5],\n",
    "                                             False, True, phonemes[-1], vb, offsets[-1], None, 386, 0))\n",
    "\n",
    "        self.requiresUpdate = np.ones(len(phonemes))\n",
    "        self.update()\n",
    "    def update(self):\n",
    "        for i in range(self.requiresUpdate.size):\n",
    "            if self.requiresUpdate[i] == 1:\n",
    "                print(i)\n",
    "                segment = self.segments[i]\n",
    "                spectrum = torch.zeros((segment.end3 - segment.start1, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "                excitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                voicedExcitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = segment.start3 - segment.start1\n",
    "                    previousSpectrum = self.segments[i-1].getSpectrum()[-1]\n",
    "                    previousVoicedExcitation = self.segments[i-1].getVoicedExcitation()[(self.segments[i-1].end1-self.segments[i-1].end3)*int(self.vb.sampleRate/75):]\n",
    "                if segment.endCap:\n",
    "                    windowEnd = segment.end3 - segment.start1\n",
    "                else:\n",
    "                    windowEnd = segment.end1 - segment.start1\n",
    "                    nextSpectrum = self.segments[i+1].getSpectrum()[0]\n",
    "                    nextVoicedExcitation = self.segments[i+1].getVoicedExcitation()[0:(self.segments[i+1].start3-self.segments[i+1].start1)*int(self.vb.sampleRate/75)]\n",
    "                \n",
    "                spectrum[windowStart:windowEnd] = segment.getSpectrum()\n",
    "                voicedExcitation = segment.getVoicedExcitation()\n",
    "                if segment.startCap == False:\n",
    "                    for j in range(segment.start3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(previousSpectrum, spectrum[windowStart], j / (segment.start3 - segment.start1))\n",
    "                    voicedExcitation[0:(segment.start3-segment.start1)*int(self.vb.sampleRate/75)] += previousVoicedExcitation\n",
    "                if segment.endCap == False:\n",
    "                    for j in range(segment.end1 - segment.start1, segment.end3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(spectrum[windowEnd], nextSpectrum, (j - segment.start1) / (segment.end3 - segment.end1))\n",
    "                    voicedExcitation[(segment.end1-segment.end3)*int(self.vb.sampleRate/75):] += nextVoicedExcitation\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = (segment.start2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    previousExcitation = self.segments[i-1].getExcitation()[(segment.start1-segment.start2)*int(self.vb.sampleRate/75):]\n",
    "                    excitation[0:windowStart] = previousExcitation\n",
    "                if segment.endCap:\n",
    "                    windowEnd = (segment.end3 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                else:\n",
    "                    windowEnd = (segment.end2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    nextExcitation = self.segments[i+1].getExcitation()[0:(segment.end3-segment.end2)*int(self.vb.sampleRate/75)]\n",
    "                    excitation[windowEnd:] = nextExcitation\n",
    "                excitation[windowStart:windowEnd] = segment.getExcitation()\n",
    "                \n",
    "                self.spectrum[segment.start1:segment.end3] = spectrum\n",
    "                self.excitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = excitation\n",
    "                self.voicedExcitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = voicedExcitation\n",
    "                \n",
    "                skipPrevious = True#implement skipPrevious\n",
    "            else:\n",
    "                skipPrevious = False\n",
    "            \n",
    "        self.synth.Synthesize(0, self.spectrum, self.excitation, self.voicedExcitation)\n",
    "    def save(self):\n",
    "        self.synth.save(\"Output_Demo.wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valid-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempVB:\n",
    "    def __init__(self):\n",
    "        self.sampleRate = 48000\n",
    "        self.phonemeDict = dict([])\n",
    "        phonemeKeys = [\"A\", \"E\", \"I\", \"O\", \"U\", \"G\", \"K\", \"N\", \"S\", \"T\"]\n",
    "        for key in phonemeKeys:\n",
    "            self.phonemeDict[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "            self.sampleRate = self.phonemeDict[key].sampleRate\n",
    "            self.phonemeDict[key].CalculatePitch(249.)\n",
    "            self.phonemeDict[key].CalculateSpectra(iterations = 15)\n",
    "            self.phonemeDict[key].CalculateExcitation()\n",
    "        self.crfAi = SpecCrfAi(learningRate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voicebank:\n",
    "    def __init__(self, vbKey):\n",
    "        self.phonemeDict = dict()\n",
    "        loaded_weights = 0#(vbKey)\n",
    "        self.crfAi = 0#SpecCrfAi(loaded_weights)\n",
    "        #load additional parameters\n",
    "        self.sampleRate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polished-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, sampleRate):\n",
    "        self.sampleRate = sampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def Synthesize(self, steadiness, spectrum, Excitation, VoicedExcitation):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        \n",
    "        #HERE + VoicedExcitation\n",
    "        \n",
    "        self.returnSignal = torch.stft(Excitation + VoicedExcitation , tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)[0:-1]\n",
    "        self.returnSignal = self.returnSignal * spectrum\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided=True)\n",
    "        del Window\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal.detach(), 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latin-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSamples = dict([])\n",
    "TrainingKeys = [\"A_E\", \"A_G\", \"A_I\", \"A_K\", \"A_N\", \"A_O\", \"A_S\", \"A_T\", \"A_U\",\n",
    "                   \"E_A\", \"E_G\", \"E_I\", \"E_K\", \"E_N\", \"E_O\", \"E_S\", \"E_T\", \"E_U\",\n",
    "                   \"I_A\", \"I_E\", \"I_G\", \"I_K\", \"I_N\", \"I_O\", \"I_S\", \"I_T\", \"I_U\",\n",
    "                   \"O_A\", \"O_E\", \"O_G\", \"O_I\", \"O_K\", \"O_N\", \"O_S\", \"O_T\", \"O_U\",\n",
    "                   \"U_A\", \"U_E\", \"U_G\", \"U_I\", \"U_K\", \"U_N\", \"U_O\", \"U_S\", \"U_T\",\n",
    "                   \"G_A\", \"G_E\", \"G_I\", \"G_O\", \"G_U\",\n",
    "                   \"K_A\", \"K_E\", \"K_I\", \"K_O\", \"K_U\",\n",
    "                   \"N_A\", \"N_E\", \"N_I\", \"N_O\", \"N_U\",\n",
    "                   \"S_A\", \"S_E\", \"S_I\", \"S_O\", \"S_U\",\n",
    "                   \"T_A\", \"T_E\", \"T_I\", \"T_O\", \"T_U\"\n",
    "                  ]\n",
    "\n",
    "for key in TrainingKeys:\n",
    "    TrainingSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    TrainingSamples[key].CalculatePitch(249.)\n",
    "    TrainingSamples[key].CalculateSpectra(iterations = 25)\n",
    "    TrainingSamples[key].CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "former-economics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5], loss:0.6699\n",
      "epoch [2/5], loss:0.3819\n",
      "epoch [3/5], loss:0.2220\n",
      "epoch [4/5], loss:0.2210\n",
      "epoch [5/5], loss:0.2040\n",
      "epoch [1/5], loss:0.0592\n",
      "epoch [2/5], loss:0.2986\n",
      "epoch [3/5], loss:0.2539\n",
      "epoch [4/5], loss:0.0732\n",
      "epoch [5/5], loss:0.1139\n",
      "epoch [1/5], loss:0.1344\n",
      "epoch [2/5], loss:0.1231\n",
      "epoch [3/5], loss:0.1600\n",
      "epoch [4/5], loss:0.1193\n",
      "epoch [5/5], loss:0.1763\n",
      "epoch [1/5], loss:0.0200\n",
      "epoch [2/5], loss:0.1188\n",
      "epoch [3/5], loss:0.0927\n",
      "epoch [4/5], loss:0.0254\n",
      "epoch [5/5], loss:0.1174\n",
      "epoch [1/5], loss:0.1287\n",
      "epoch [2/5], loss:0.1168\n",
      "epoch [3/5], loss:0.1131\n",
      "epoch [4/5], loss:0.1022\n",
      "epoch [5/5], loss:0.0677\n",
      "epoch [1/5], loss:0.1434\n",
      "epoch [2/5], loss:0.0827\n",
      "epoch [3/5], loss:0.0629\n",
      "epoch [4/5], loss:0.0931\n",
      "epoch [5/5], loss:0.0520\n",
      "epoch [1/5], loss:0.3391\n",
      "epoch [2/5], loss:0.1440\n",
      "epoch [3/5], loss:0.1812\n",
      "epoch [4/5], loss:0.1488\n",
      "epoch [5/5], loss:0.2153\n",
      "epoch [1/5], loss:0.0166\n",
      "epoch [2/5], loss:0.1064\n",
      "epoch [3/5], loss:0.0692\n",
      "epoch [4/5], loss:0.1176\n",
      "epoch [5/5], loss:0.1063\n",
      "epoch [1/5], loss:0.1077\n",
      "epoch [2/5], loss:0.1446\n",
      "epoch [3/5], loss:0.0578\n",
      "epoch [4/5], loss:0.0792\n",
      "epoch [5/5], loss:0.0805\n",
      "epoch [1/5], loss:0.1865\n",
      "epoch [2/5], loss:0.1072\n",
      "epoch [3/5], loss:0.0929\n",
      "epoch [4/5], loss:0.0975\n",
      "epoch [5/5], loss:0.0848\n",
      "epoch [1/5], loss:0.1674\n",
      "epoch [2/5], loss:0.0753\n",
      "epoch [3/5], loss:0.0927\n",
      "epoch [4/5], loss:0.0744\n",
      "epoch [5/5], loss:0.0950\n",
      "epoch [1/5], loss:0.0868\n",
      "epoch [2/5], loss:0.0775\n",
      "epoch [3/5], loss:0.0680\n",
      "epoch [4/5], loss:0.1101\n",
      "epoch [5/5], loss:0.0783\n",
      "epoch [1/5], loss:0.0964\n",
      "epoch [2/5], loss:0.0691\n",
      "epoch [3/5], loss:0.0253\n",
      "epoch [4/5], loss:0.0721\n",
      "epoch [5/5], loss:0.0359\n",
      "epoch [1/5], loss:0.1061\n",
      "epoch [2/5], loss:0.0536\n",
      "epoch [3/5], loss:0.0585\n",
      "epoch [4/5], loss:0.0680\n",
      "epoch [5/5], loss:0.0689\n",
      "epoch [1/5], loss:0.1972\n",
      "epoch [2/5], loss:0.1959\n",
      "epoch [3/5], loss:0.1675\n",
      "epoch [4/5], loss:0.0847\n",
      "epoch [5/5], loss:0.0675\n",
      "epoch [1/5], loss:0.1109\n",
      "epoch [2/5], loss:0.1212\n",
      "epoch [3/5], loss:0.0860\n",
      "epoch [4/5], loss:0.0888\n",
      "epoch [5/5], loss:0.0934\n",
      "epoch [1/5], loss:0.0194\n",
      "epoch [2/5], loss:0.0702\n",
      "epoch [3/5], loss:0.2497\n",
      "epoch [4/5], loss:0.3660\n",
      "epoch [5/5], loss:0.0459\n",
      "epoch [1/5], loss:0.0926\n",
      "epoch [2/5], loss:0.0564\n",
      "epoch [3/5], loss:0.0690\n",
      "epoch [4/5], loss:0.0850\n",
      "epoch [5/5], loss:0.0940\n",
      "epoch [1/5], loss:0.0934\n",
      "epoch [2/5], loss:0.0968\n",
      "epoch [3/5], loss:0.1266\n",
      "epoch [4/5], loss:0.0830\n",
      "epoch [5/5], loss:0.0667\n",
      "epoch [1/5], loss:0.1214\n",
      "epoch [2/5], loss:0.0780\n",
      "epoch [3/5], loss:0.0929\n",
      "epoch [4/5], loss:0.0710\n",
      "epoch [5/5], loss:0.0655\n",
      "epoch [1/5], loss:0.0582\n",
      "epoch [2/5], loss:0.0307\n",
      "epoch [3/5], loss:0.0169\n",
      "epoch [4/5], loss:0.0637\n",
      "epoch [5/5], loss:0.0245\n",
      "epoch [1/5], loss:0.1019\n",
      "epoch [2/5], loss:0.0083\n",
      "epoch [3/5], loss:0.0087\n",
      "epoch [4/5], loss:0.0429\n",
      "epoch [5/5], loss:0.0056\n",
      "epoch [1/5], loss:0.0764\n",
      "epoch [2/5], loss:0.0492\n",
      "epoch [3/5], loss:0.0629\n",
      "epoch [4/5], loss:0.0408\n",
      "epoch [5/5], loss:0.0454\n",
      "epoch [1/5], loss:0.0831\n",
      "epoch [2/5], loss:0.1146\n",
      "epoch [3/5], loss:0.0992\n",
      "epoch [4/5], loss:0.0445\n",
      "epoch [5/5], loss:0.1091\n",
      "epoch [1/5], loss:0.1787\n",
      "epoch [2/5], loss:0.0664\n",
      "epoch [3/5], loss:0.1536\n",
      "epoch [4/5], loss:0.0550\n",
      "epoch [5/5], loss:0.1401\n",
      "epoch [1/5], loss:0.0395\n",
      "epoch [2/5], loss:0.0221\n",
      "epoch [3/5], loss:0.0330\n",
      "epoch [4/5], loss:0.0525\n",
      "epoch [5/5], loss:0.0132\n",
      "epoch [1/5], loss:0.0640\n",
      "epoch [2/5], loss:0.0621\n",
      "epoch [3/5], loss:0.0422\n",
      "epoch [4/5], loss:0.0354\n",
      "epoch [5/5], loss:0.0324\n",
      "epoch [1/5], loss:0.1173\n",
      "epoch [2/5], loss:0.0724\n",
      "epoch [3/5], loss:0.1177\n",
      "epoch [4/5], loss:0.0568\n",
      "epoch [5/5], loss:0.0574\n",
      "epoch [1/5], loss:0.0490\n",
      "epoch [2/5], loss:0.1025\n",
      "epoch [3/5], loss:0.0992\n",
      "epoch [4/5], loss:0.0874\n",
      "epoch [5/5], loss:0.0435\n",
      "epoch [1/5], loss:0.1074\n",
      "epoch [2/5], loss:0.1265\n",
      "epoch [3/5], loss:0.0468\n",
      "epoch [4/5], loss:0.0074\n",
      "epoch [5/5], loss:0.0554\n",
      "epoch [1/5], loss:0.1513\n",
      "epoch [2/5], loss:0.0634\n",
      "epoch [3/5], loss:0.0442\n",
      "epoch [4/5], loss:0.0573\n",
      "epoch [5/5], loss:0.0668\n",
      "epoch [1/5], loss:0.0138\n",
      "epoch [2/5], loss:0.0109\n",
      "epoch [3/5], loss:0.0417\n",
      "epoch [4/5], loss:0.0510\n",
      "epoch [5/5], loss:0.0472\n",
      "epoch [1/5], loss:0.0701\n",
      "epoch [2/5], loss:0.0639\n",
      "epoch [3/5], loss:0.0481\n",
      "epoch [4/5], loss:0.0555\n",
      "epoch [5/5], loss:0.0550\n",
      "epoch [1/5], loss:0.0856\n",
      "epoch [2/5], loss:0.0700\n",
      "epoch [3/5], loss:0.0843\n",
      "epoch [4/5], loss:0.0583\n",
      "epoch [5/5], loss:0.0916\n",
      "epoch [1/5], loss:0.0732\n",
      "epoch [2/5], loss:0.0551\n",
      "epoch [3/5], loss:0.1119\n",
      "epoch [4/5], loss:0.0771\n",
      "epoch [5/5], loss:0.0510\n",
      "epoch [1/5], loss:0.0704\n",
      "epoch [2/5], loss:0.0585\n",
      "epoch [3/5], loss:0.0706\n",
      "epoch [4/5], loss:0.0457\n",
      "epoch [5/5], loss:0.0537\n",
      "epoch [1/5], loss:0.1284\n",
      "epoch [2/5], loss:0.0788\n",
      "epoch [3/5], loss:0.3258\n",
      "epoch [4/5], loss:0.1180\n",
      "epoch [5/5], loss:0.0741\n",
      "epoch [1/5], loss:0.0867\n",
      "epoch [2/5], loss:0.0811\n",
      "epoch [3/5], loss:0.0590\n",
      "epoch [4/5], loss:0.0816\n",
      "epoch [5/5], loss:0.0535\n",
      "epoch [1/5], loss:0.0786\n",
      "epoch [2/5], loss:0.0548\n",
      "epoch [3/5], loss:0.0626\n",
      "epoch [4/5], loss:0.0155\n",
      "epoch [5/5], loss:0.0143\n",
      "epoch [1/5], loss:0.0476\n",
      "epoch [2/5], loss:0.0551\n",
      "epoch [3/5], loss:0.0792\n",
      "epoch [4/5], loss:0.0351\n",
      "epoch [5/5], loss:0.0170\n",
      "epoch [1/5], loss:0.0079\n",
      "epoch [2/5], loss:0.0479\n",
      "epoch [3/5], loss:0.0239\n",
      "epoch [4/5], loss:0.0357\n",
      "epoch [5/5], loss:0.0626\n",
      "epoch [1/5], loss:0.1014\n",
      "epoch [2/5], loss:0.0607\n",
      "epoch [3/5], loss:0.0959\n",
      "epoch [4/5], loss:0.0981\n",
      "epoch [5/5], loss:0.0555\n",
      "epoch [1/5], loss:0.1221\n",
      "epoch [2/5], loss:0.0363\n",
      "epoch [3/5], loss:0.0624\n",
      "epoch [4/5], loss:0.0503\n",
      "epoch [5/5], loss:0.0408\n",
      "epoch [1/5], loss:0.0804\n",
      "epoch [2/5], loss:0.1093\n",
      "epoch [3/5], loss:0.0615\n",
      "epoch [4/5], loss:0.0454\n",
      "epoch [5/5], loss:0.1120\n",
      "epoch [1/5], loss:0.0138\n",
      "epoch [2/5], loss:0.0904\n",
      "epoch [3/5], loss:0.0080\n",
      "epoch [4/5], loss:0.0935\n",
      "epoch [5/5], loss:0.0060\n",
      "epoch [1/5], loss:0.1225\n",
      "epoch [2/5], loss:0.2090\n",
      "epoch [3/5], loss:0.0961\n",
      "epoch [4/5], loss:0.1007\n",
      "epoch [5/5], loss:0.1057\n",
      "epoch [1/5], loss:0.1087\n",
      "epoch [2/5], loss:0.0880\n",
      "epoch [3/5], loss:0.0949\n",
      "epoch [4/5], loss:0.0846\n",
      "epoch [5/5], loss:0.0833\n",
      "epoch [1/5], loss:0.1403\n",
      "epoch [2/5], loss:0.1317\n",
      "epoch [3/5], loss:0.0901\n",
      "epoch [4/5], loss:0.1100\n",
      "epoch [5/5], loss:0.0598\n",
      "epoch [1/5], loss:0.1616\n",
      "epoch [2/5], loss:0.2134\n",
      "epoch [3/5], loss:0.0931\n",
      "epoch [4/5], loss:0.1005\n",
      "epoch [5/5], loss:0.0819\n",
      "epoch [1/5], loss:0.0944\n",
      "epoch [2/5], loss:0.0721\n",
      "epoch [3/5], loss:0.0674\n",
      "epoch [4/5], loss:0.0515\n",
      "epoch [5/5], loss:0.0365\n",
      "epoch [1/5], loss:0.2054\n",
      "epoch [2/5], loss:0.0975\n",
      "epoch [3/5], loss:0.0859\n",
      "epoch [4/5], loss:0.0772\n",
      "epoch [5/5], loss:0.0445\n",
      "epoch [1/5], loss:0.1284\n",
      "epoch [2/5], loss:0.0953\n",
      "epoch [3/5], loss:0.1194\n",
      "epoch [4/5], loss:0.0564\n",
      "epoch [5/5], loss:0.0681\n",
      "epoch [1/5], loss:0.1129\n",
      "epoch [2/5], loss:0.1186\n",
      "epoch [3/5], loss:0.0824\n",
      "epoch [4/5], loss:0.0527\n",
      "epoch [5/5], loss:0.0713\n",
      "epoch [1/5], loss:0.1110\n",
      "epoch [2/5], loss:0.0698\n",
      "epoch [3/5], loss:0.0387\n",
      "epoch [4/5], loss:0.0722\n",
      "epoch [5/5], loss:0.0669\n",
      "epoch [1/5], loss:0.0981\n",
      "epoch [2/5], loss:0.0781\n",
      "epoch [3/5], loss:0.0587\n",
      "epoch [4/5], loss:0.0431\n",
      "epoch [5/5], loss:0.0382\n",
      "epoch [1/5], loss:0.1977\n",
      "epoch [2/5], loss:0.0863\n",
      "epoch [3/5], loss:0.1127\n",
      "epoch [4/5], loss:0.0692\n",
      "epoch [5/5], loss:0.0709\n",
      "epoch [1/5], loss:0.0790\n",
      "epoch [2/5], loss:0.0759\n",
      "epoch [3/5], loss:0.0780\n",
      "epoch [4/5], loss:0.0517\n",
      "epoch [5/5], loss:0.0666\n",
      "epoch [1/5], loss:0.0598\n",
      "epoch [2/5], loss:0.0589\n",
      "epoch [3/5], loss:0.0370\n",
      "epoch [4/5], loss:0.0592\n",
      "epoch [5/5], loss:0.0341\n",
      "epoch [1/5], loss:0.0467\n",
      "epoch [2/5], loss:0.0356\n",
      "epoch [3/5], loss:0.0597\n",
      "epoch [4/5], loss:0.0278\n",
      "epoch [5/5], loss:0.0418\n",
      "epoch [1/5], loss:0.0760\n",
      "epoch [2/5], loss:0.0308\n",
      "epoch [3/5], loss:0.0231\n",
      "epoch [4/5], loss:0.0224\n",
      "epoch [5/5], loss:0.0231\n",
      "epoch [1/5], loss:0.1193\n",
      "epoch [2/5], loss:0.2534\n",
      "epoch [3/5], loss:0.1488\n",
      "epoch [4/5], loss:0.1163\n",
      "epoch [5/5], loss:0.0731\n",
      "epoch [1/5], loss:0.2752\n",
      "epoch [2/5], loss:0.1506\n",
      "epoch [3/5], loss:0.1285\n",
      "epoch [4/5], loss:0.1490\n",
      "epoch [5/5], loss:0.1544\n",
      "epoch [1/5], loss:0.1007\n",
      "epoch [2/5], loss:0.2181\n",
      "epoch [3/5], loss:0.1230\n",
      "epoch [4/5], loss:0.0909\n",
      "epoch [5/5], loss:0.0662\n",
      "epoch [1/5], loss:0.1540\n",
      "epoch [2/5], loss:0.1250\n",
      "epoch [3/5], loss:0.1522\n",
      "epoch [4/5], loss:0.0866\n",
      "epoch [5/5], loss:0.0721\n",
      "epoch [1/5], loss:0.1379\n",
      "epoch [2/5], loss:0.1128\n",
      "epoch [3/5], loss:0.0790\n",
      "epoch [4/5], loss:0.1049\n",
      "epoch [5/5], loss:0.0928\n",
      "epoch [1/5], loss:0.2000\n",
      "epoch [2/5], loss:0.1116\n",
      "epoch [3/5], loss:0.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/5], loss:0.0757\n",
      "epoch [5/5], loss:0.0566\n",
      "epoch [1/5], loss:0.1489\n",
      "epoch [2/5], loss:0.0663\n",
      "epoch [3/5], loss:0.0957\n",
      "epoch [4/5], loss:0.0819\n",
      "epoch [5/5], loss:0.0522\n",
      "epoch [1/5], loss:0.0951\n",
      "epoch [2/5], loss:0.0939\n",
      "epoch [3/5], loss:0.0823\n",
      "epoch [4/5], loss:0.0563\n",
      "epoch [5/5], loss:0.0511\n",
      "epoch [1/5], loss:0.0977\n",
      "epoch [2/5], loss:0.0871\n",
      "epoch [3/5], loss:0.0775\n",
      "epoch [4/5], loss:0.0526\n",
      "epoch [5/5], loss:0.0427\n",
      "epoch [1/5], loss:0.0609\n",
      "epoch [2/5], loss:0.0959\n",
      "epoch [3/5], loss:0.0518\n",
      "epoch [4/5], loss:0.0486\n",
      "epoch [5/5], loss:0.0553\n"
     ]
    }
   ],
   "source": [
    "trainSpectra = []\n",
    "i = 0\n",
    "for key in TrainingKeys:\n",
    "    trainSpectra.append(torch.empty_like(TrainingSamples[key].spectra))\n",
    "    for j in range(TrainingSamples[key].spectra.size()[0]):\n",
    "        trainSpectra[i][j] = TrainingSamples[key].spectrum + TrainingSamples[key].spectra[j]\n",
    "    i += 1\n",
    "\n",
    "vb = TempVB()\n",
    "for i in range(70):\n",
    "    vb.crfAi.train(trainSpectra[i], epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "directed-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25600 48363 35 52\n",
      "0 47484 0 37\n",
      "1\n",
      "0 47484 0 37\n",
      "25600 75650 40 79\n",
      "25600 48363 35 52\n",
      "2\n",
      "25600 48363 35 52\n",
      "0 14417 75 86\n",
      "25600 75650 40 79\n",
      "3\n",
      "25600 75650 40 79\n",
      "16640 78240 82 130\n",
      "0 14417 75 86\n",
      "4\n",
      "0 14417 75 86\n",
      "16640 78240 82 130\n"
     ]
    }
   ],
   "source": [
    "borders = [0, 1, 2,\n",
    "           35, 36, 37,\n",
    "           40, 51, 52,\n",
    "           75, 76, 79,\n",
    "           82, 83, 86,\n",
    "           128, 129, 130\n",
    "          ]\n",
    "phonemes = [\"A\", \"N\", \"A\", \"T\", \"A\"]\n",
    "#offsets = [0, 5, 1, 1, 1]\n",
    "offsets = [0, 20, 20, 0, 13]\n",
    "\n",
    "sequence = VocalSequence(0, 400, vb, borders, phonemes, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "velvet-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "secret-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c4c8f9e20>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.spectrum[31].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "strange-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c4c6b6040>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.synth.returnSignal.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-crime",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
