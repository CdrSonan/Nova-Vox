{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jokla\\anaconda3\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float)\n",
    "        self.voicedExcitation = torch.tensor([], dtype = float)\n",
    "        self.VoicedExcitations = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "        \n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 10, preIterations = 2):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        signalsAbs = signals.abs()\n",
    "        \n",
    "        workingSpectra = torch.sqrt(signalsAbs)\n",
    "        \n",
    "        workingSpectra = torch.max(workingSpectra, torch.tensor([-100]))\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        \n",
    "        for j in range(preIterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.VoicedExcitations = torch.zeros_like(signals)\n",
    "        for i in range(signals.size()[0]):\n",
    "            for j in range(signals.size()[1]):\n",
    "                if torch.sqrt(signalsAbs[i][j]) > self.spectra[i][j]:\n",
    "                    self.VoicedExcitations[i][j] = signals[i][j]\n",
    "                \n",
    "        for j in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        \n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        #return torch.log(signalsAbs)\n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "        \n",
    "    def CalculateExcitation(self, filterWidth = 10):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        signals = torch.stft(self.waveform, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "            self.VoicedExcitations[i] = self.VoicedExcitations[i] / torch.square(self.spectrum + self.spectra[i])\n",
    "        \n",
    "        VoicedExcitations = torch.transpose(self.VoicedExcitations, 0, 1)\n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        self.voicedExcitation = torch.istft(VoicedExcitations, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided = True)\n",
    "        \n",
    "        self.excitation = self.excitation - self.voicedExcitation\n",
    "        self.excitation = torch.stft(self.excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        \n",
    "        self.excitation = torch.transpose(self.excitation, 0, 1)\n",
    "        \n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expired-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(RelLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, targets):    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        differences = torch.abs(inputs - targets)\n",
    "        sums = torch.abs(inputs + targets)\n",
    "        out = (differences / sums).sum() / inputs.size()[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configured-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi(nn.Module):\n",
    "    def __init__(self, learningRate=1e-4):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Linear(3843, 3843)\n",
    "        self.ReLu1 = nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(3843, 5763)\n",
    "        self.ReLu2 = nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(5763, 3842)\n",
    "        self.ReLu3 = nn.ReLU()\n",
    "        self.layer4 = torch.nn.Linear(3842, 1921)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #self.criterion = RelLoss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.tensor([factor])\n",
    "        x = torch.cat((spectrum1, spectrum2, fac), dim = 0)\n",
    "        x = x.float()#.unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.ReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        output = torch.square(torch.squeeze(self(torch.sqrt(spectrum1), torch.sqrt(spectrum2), factor)))\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                indexList = np.arange(0, data.size()[0], 1)\n",
    "                np.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "black-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSegment:\n",
    "    def __init__(self, start1, start2, start3, end1, end2, end3, startCap, endCap, phonemeKey, vb, offset, repetititionSpacing, pitch, steadiness):\n",
    "        self.start1 = start1\n",
    "        self.start2 = start2\n",
    "        self.start3 = start3\n",
    "        self.end1 = end1\n",
    "        self.end2 = end2\n",
    "        self.end3 = end3\n",
    "        self.startCap = startCap\n",
    "        self.endCap = endCap\n",
    "        self.phonemeKey = phonemeKey\n",
    "        self.vb = vb\n",
    "        self.offset = offset\n",
    "        self.repetititionSpacing = repetititionSpacing\n",
    "        self.pitch = pitch\n",
    "        self.steadiness = steadiness\n",
    "        \n",
    "    def getSpectrum(self):\n",
    "        if self.startCap:\n",
    "            windowStart = self.offset\n",
    "        else:\n",
    "            windowStart = self.start3 - self.start1 + self.offset\n",
    "        if self.endCap:\n",
    "            windowEnd = self.end3 - self.start1 + self.offset\n",
    "        else:\n",
    "            windowEnd = self.end1 - self.start1 + self.offset\n",
    "        spectrum =  self.vb.phonemeDict[self.phonemeKey].spectrum#implement looping\n",
    "        spectra =  self.vb.phonemeDict[self.phonemeKey].spectra[windowStart:windowEnd]\n",
    "        return torch.square(spectrum + (math.pow(1 - self.steadiness, 2) * spectra))\n",
    "    \n",
    "    def getExcitation(self):\n",
    "        BatchSize = int(self.vb.sampleRate / 75)\n",
    "        tripleBatchSize = int(self.vb.sampleRate / 25)\n",
    "        premul = self.vb.phonemeDict[self.phonemeKey].excitation.size()[0] / (self.end3 - self.start1 + 1)\n",
    "        #premul = 1\n",
    "        if self.startCap:\n",
    "            windowStart = math.floor(self.offset * premul)\n",
    "            length = -self.start1\n",
    "        else:\n",
    "            windowStart = math.floor((self.start2 - self.start1 + self.offset) * premul)\n",
    "            length = -self.start2\n",
    "        if self.endCap:\n",
    "            windowEnd = math.ceil((self.end3 - self.start1 + self.offset) * premul)\n",
    "            length += self.end3\n",
    "        else:\n",
    "            windowEnd = math.ceil((self.end2 - self.start1 + self.offset) * premul)\n",
    "            length += self.end2\n",
    "        excitation = self.vb.phonemeDict[self.phonemeKey].excitation[windowStart:windowEnd]\n",
    "        excitation = torch.transpose(excitation, 0, 1)\n",
    "        transform = torchaudio.transforms.TimeStretch(hop_length = int(self.vb.sampleRate / 75),\n",
    "                                                      n_freq = int(self.vb.sampleRate / 25 / 2) + 1, \n",
    "                                                      fixed_rate = premul)\n",
    "        excitation = transform(torch.view_as_real(excitation))\n",
    "        excitation = torch.view_as_complex(excitation)\n",
    "        window = torch.hann_window(int(self.vb.sampleRate / 25))\n",
    "        excitation = torch.istft(excitation, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = window, onesided = True, length = length*int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        \"\"\"slope = torch.linspace(0, 1, (self.start3 - self.start1) * int(self.vb.sampleRate / 75))\n",
    "        voicedExcitation[0:(self.start3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        slope = torch.linspace(1, 0, (self.end3 - self.end1) * int(self.vb.sampleRate / 75))\n",
    "        voicedExcitation[(self.end1 - self.start1) * int(self.vb.sampleRate / 75):(self.end3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\"\"\"\n",
    "        \n",
    "        return excitation[0:length*int(self.vb.sampleRate / 75)]\n",
    "    \n",
    "    def getVoicedExcitation(self):\n",
    "        nativePitch = self.vb.phonemeDict[self.phonemeKey].pitch\n",
    "        #nativePitch = self.vb.phonemeDict[self.phonemeKey].pitches[...]\n",
    "        #pitch = nativePitch + self.vb.phonemeDict[phonemeKey].pitches...\n",
    "        premul = self.pitch / nativePitch * self.vb.sampleRate / 75\n",
    "        windowStart = math.floor(self.offset * premul)\n",
    "        windowEnd = math.ceil((self.end3 - self.start1 + self.offset) * premul)\n",
    "        voicedExcitation = self.vb.phonemeDict[self.phonemeKey].voicedExcitation[windowStart:windowEnd]\n",
    "        transform = torchaudio.transforms.Resample(orig_freq = nativePitch,#self.pitch,\n",
    "                                                   new_freq = self.pitch,#nativePitch,\n",
    "                                                   resampling_method = 'sinc_interpolation')\n",
    "        voicedExcitation = transform(voicedExcitation)\n",
    "        if self.startCap == False:\n",
    "            slope = torch.linspace(0, 1, (self.start3 - self.start1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[0:(self.start3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        if self.endCap == False:\n",
    "            slope = torch.linspace(1, 0, (self.end3 - self.end1) * int(self.vb.sampleRate / 75))\n",
    "            voicedExcitation[(self.end1 - self.start1) * int(self.vb.sampleRate / 75):(self.end3 - self.start1) * int(self.vb.sampleRate / 75)] *= slope\n",
    "        \n",
    "        return voicedExcitation[0:(self.end3 - self.start1) * int(self.vb.sampleRate / 75)]\n",
    "        #resample segments\n",
    "        #individual fourier transform\n",
    "        #istft\n",
    "        #windowing adaptive to borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalSequence:\n",
    "    def __init__(self, start, end, vb, borders, phonemes, offsets):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.vb = vb\n",
    "        self.synth = Synthesizer(self.vb.sampleRate)\n",
    "        \n",
    "        self.spectrum = torch.zeros((self.end - self.start, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "        self.excitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        self.voicedExcitation = torch.zeros((self.end - self.start) * int(self.vb.sampleRate / 75))\n",
    "        \n",
    "        self.segments = []\n",
    "        if len(phonemes)== 1:#rewrite border system to use tensor, implement pitch and steadiness\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, True, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "        else:\n",
    "            self.segments.append(VocalSegment(borders[0], borders[1], borders[2], borders[3], borders[4], borders[5],\n",
    "                                             True, False, phonemes[0], vb, offsets[0], None, 386, 0))\n",
    "            for i in range(1, len(phonemes)-1):\n",
    "                self.segments.append(VocalSegment(borders[3*i], borders[3*i+1], borders[3*i+2], borders[3*i+3], borders[3*i+4], borders[3*i+5],\n",
    "                                                  False, False, phonemes[i], vb, offsets[i], None, 386, 0))\n",
    "            endpoint = len(phonemes)-1\n",
    "            self.segments.append(VocalSegment(borders[3*endpoint], borders[3*endpoint+1], borders[3*endpoint+2], borders[3*endpoint+3], borders[3*endpoint+4], borders[3*endpoint+5],\n",
    "                                             False, True, phonemes[-1], vb, offsets[-1], None, 386, 0))\n",
    "\n",
    "        self.requiresUpdate = np.ones(len(phonemes))\n",
    "        self.update()\n",
    "    def update(self):\n",
    "        for i in range(self.requiresUpdate.size):\n",
    "            if self.requiresUpdate[i] == 1:\n",
    "                print(i)\n",
    "                segment = self.segments[i]\n",
    "                spectrum = torch.zeros((segment.end3 - segment.start1, int(self.vb.sampleRate / 25 / 2) + 1))\n",
    "                excitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                voicedExcitation = torch.zeros((segment.end3 - segment.start1) * int(self.vb.sampleRate / 75))\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = segment.start3 - segment.start1\n",
    "                    previousSpectrum = self.segments[i-1].getSpectrum()[-1]\n",
    "                    previousVoicedExcitation = self.segments[i-1].getVoicedExcitation()[(self.segments[i-1].end1-self.segments[i-1].end3)*int(self.vb.sampleRate/75):]\n",
    "                if segment.endCap:\n",
    "                    windowEnd = segment.end3 - segment.start1\n",
    "                else:\n",
    "                    windowEnd = segment.end1 - segment.start1\n",
    "                    nextSpectrum = self.segments[i+1].getSpectrum()[0]\n",
    "                    nextVoicedExcitation = self.segments[i-1].getVoicedExcitation()[0:(self.segments[i+1].start3-self.segments[i+1].start1)*int(self.vb.sampleRate/75)]\n",
    "                \n",
    "                spectrum[windowStart:windowEnd] = segment.getSpectrum()\n",
    "                voicedExcitation = segment.getVoicedExcitation()\n",
    "                if segment.startCap == False:\n",
    "                    for j in range(segment.start3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(previousSpectrum, spectrum[windowStart], j / (segment.start3 - segment.start1))\n",
    "                    voicedExcitation[0:(segment.start3-segment.start1)*int(self.vb.sampleRate/75)] += previousVoicedExcitation\n",
    "                if segment.endCap == False:\n",
    "                    for j in range(segment.end1 - segment.start1, segment.end3 - segment.start1):\n",
    "                        spectrum[j] = self.vb.crfAi.processData(spectrum[windowEnd], nextSpectrum, (j - segment.start1) / (segment.end3 - segment.end1))\n",
    "                    voicedExcitation[(segment.end1-segment.end3)*int(self.vb.sampleRate/75):] += nextVoicedExcitation\n",
    "                if segment.startCap:\n",
    "                    windowStart = 0\n",
    "                else:\n",
    "                    windowStart = (segment.start2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    previousExcitation = self.segments[i-1].getExcitation()[(segment.start1-segment.start2)*int(self.vb.sampleRate/75):]\n",
    "                    excitation[0:windowStart] = previousExcitation\n",
    "                if segment.endCap:\n",
    "                    windowEnd = (segment.end3 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                else:\n",
    "                    windowEnd = (segment.end2 - segment.start1) * int(self.vb.sampleRate / 75)\n",
    "                    nextExcitation = self.segments[i+1].getExcitation()[0:(segment.end3-segment.end2)*int(self.vb.sampleRate/75)]\n",
    "                    excitation[windowEnd:] = nextExcitation\n",
    "                excitation[windowStart:windowEnd] = segment.getExcitation()\n",
    "                \n",
    "                self.spectrum[segment.start1:segment.end3] = spectrum\n",
    "                self.excitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = excitation\n",
    "                self.voicedExcitation[segment.start1*int(self.vb.sampleRate/75):segment.end3*int(self.vb.sampleRate/75)] = voicedExcitation\n",
    "                \n",
    "                skipPrevious = True#implement skipPrevious\n",
    "            else:\n",
    "                skipPrevious = False\n",
    "            \n",
    "        self.synth.Synthesize(0, self.spectrum, self.excitation, self.voicedExcitation)\n",
    "    def save(self):\n",
    "        self.synth.save(\"Output_Demo.wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valid-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempVB:\n",
    "    def __init__(self):\n",
    "        self.sampleRate = 48000\n",
    "        self.phonemeDict = dict([])\n",
    "        phonemeKeys = [\"A\", \"E\", \"I\", \"O\", \"U\", \"G\", \"K\", \"N\", \"S\", \"T\"]\n",
    "        for key in phonemeKeys:\n",
    "            self.phonemeDict[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "            self.sampleRate = self.phonemeDict[key].sampleRate\n",
    "            self.phonemeDict[key].CalculatePitch(249.)\n",
    "            self.phonemeDict[key].CalculateSpectra(iterations = 15)\n",
    "            self.phonemeDict[key].CalculateExcitation()\n",
    "        self.crfAi = SpecCrfAi(learningRate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voicebank:\n",
    "    def __init__(self, vbKey):\n",
    "        self.phonemeDict = dict()\n",
    "        loaded_weights = 0#(vbKey)\n",
    "        self.crfAi = 0#SpecCrfAi(loaded_weights)\n",
    "        #load additional parameters\n",
    "        self.sampleRate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polished-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, sampleRate):\n",
    "        self.sampleRate = sampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def Synthesize(self, steadiness, spectrum, Excitation, VoicedExcitation):\n",
    "        tripleBatchSize = int(self.sampleRate / 25)\n",
    "        BatchSize = int(self.sampleRate / 75)\n",
    "        Window = torch.hann_window(tripleBatchSize)\n",
    "        \n",
    "        #HERE + VoicedExcitation\n",
    "        \n",
    "        self.returnSignal = torch.stft(Excitation + VoicedExcitation , tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, return_complex = True, onesided = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)[0:-1]\n",
    "        self.returnSignal = self.returnSignal * spectrum\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, tripleBatchSize, hop_length = BatchSize, win_length = tripleBatchSize, window = Window, onesided=True)\n",
    "        del Window\n",
    "        \n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal.detach(), 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latin-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSamples = dict([])\n",
    "TrainingKeys = [\"A_E\", \"A_G\", \"A_I\", \"A_K\", \"A_N\", \"A_O\", \"A_S\", \"A_T\", \"A_U\",\n",
    "                   \"E_A\", \"E_G\", \"E_I\", \"E_K\", \"E_N\", \"E_O\", \"E_S\", \"E_T\", \"E_U\",\n",
    "                   \"I_A\", \"I_E\", \"I_G\", \"I_K\", \"I_N\", \"I_O\", \"I_S\", \"I_T\", \"I_U\",\n",
    "                   \"O_A\", \"O_E\", \"O_G\", \"O_I\", \"O_K\", \"O_N\", \"O_S\", \"O_T\", \"O_U\",\n",
    "                   \"U_A\", \"U_E\", \"U_G\", \"U_I\", \"U_K\", \"U_N\", \"U_O\", \"U_S\", \"U_T\",\n",
    "                   \"G_A\", \"G_E\", \"G_I\", \"G_O\", \"G_U\",\n",
    "                   \"K_A\", \"K_E\", \"K_I\", \"K_O\", \"K_U\",\n",
    "                   \"N_A\", \"N_E\", \"N_I\", \"N_O\", \"N_U\",\n",
    "                   \"S_A\", \"S_E\", \"S_I\", \"S_O\", \"S_U\",\n",
    "                   \"T_A\", \"T_E\", \"T_I\", \"T_O\", \"T_U\"\n",
    "                  ]\n",
    "\n",
    "for key in TrainingKeys:\n",
    "    TrainingSamples[key] = AudioSample(\"Samples_rip/\"+key+\".wav\")\n",
    "    TrainingSamples[key].CalculatePitch(249.)\n",
    "    TrainingSamples[key].CalculateSpectra(iterations = 25)\n",
    "    TrainingSamples[key].CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "former-economics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/2], loss:0.6307\n",
      "epoch [2/2], loss:0.3376\n",
      "epoch [1/2], loss:0.0861\n",
      "epoch [2/2], loss:0.3007\n",
      "epoch [1/2], loss:0.3947\n",
      "epoch [2/2], loss:0.2269\n",
      "epoch [1/2], loss:0.2427\n",
      "epoch [2/2], loss:0.1293\n",
      "epoch [1/2], loss:0.1501\n",
      "epoch [2/2], loss:0.1344\n",
      "epoch [1/2], loss:0.1345\n",
      "epoch [2/2], loss:0.0856\n",
      "epoch [1/2], loss:0.3162\n",
      "epoch [2/2], loss:0.2215\n",
      "epoch [1/2], loss:0.1047\n",
      "epoch [2/2], loss:0.3116\n",
      "epoch [1/2], loss:0.1117\n",
      "epoch [2/2], loss:0.1034\n",
      "epoch [1/2], loss:0.1645\n",
      "epoch [2/2], loss:0.1051\n",
      "epoch [1/2], loss:0.0940\n",
      "epoch [2/2], loss:0.0864\n",
      "epoch [1/2], loss:0.0956\n",
      "epoch [2/2], loss:0.1044\n",
      "epoch [1/2], loss:0.1807\n",
      "epoch [2/2], loss:0.0185\n",
      "epoch [1/2], loss:0.1181\n",
      "epoch [2/2], loss:0.0575\n",
      "epoch [1/2], loss:0.1648\n",
      "epoch [2/2], loss:0.1608\n",
      "epoch [1/2], loss:0.2316\n",
      "epoch [2/2], loss:0.1027\n",
      "epoch [1/2], loss:0.0808\n",
      "epoch [2/2], loss:0.1322\n",
      "epoch [1/2], loss:0.2700\n",
      "epoch [2/2], loss:0.1613\n",
      "epoch [1/2], loss:0.1145\n",
      "epoch [2/2], loss:0.1104\n",
      "epoch [1/2], loss:0.1943\n",
      "epoch [2/2], loss:0.1289\n",
      "epoch [1/2], loss:0.0875\n",
      "epoch [2/2], loss:0.0620\n",
      "epoch [1/2], loss:0.0735\n",
      "epoch [2/2], loss:0.0145\n",
      "epoch [1/2], loss:0.2545\n",
      "epoch [2/2], loss:0.2518\n",
      "epoch [1/2], loss:0.1642\n",
      "epoch [2/2], loss:0.1909\n",
      "epoch [1/2], loss:0.2167\n",
      "epoch [2/2], loss:0.1496\n",
      "epoch [1/2], loss:0.1361\n",
      "epoch [2/2], loss:0.0235\n",
      "epoch [1/2], loss:0.0753\n",
      "epoch [2/2], loss:0.0627\n",
      "epoch [1/2], loss:0.3039\n",
      "epoch [2/2], loss:0.2616\n",
      "epoch [1/2], loss:0.1005\n",
      "epoch [2/2], loss:0.0961\n",
      "epoch [1/2], loss:0.1232\n",
      "epoch [2/2], loss:0.0912\n",
      "epoch [1/2], loss:0.0877\n",
      "epoch [2/2], loss:0.1841\n",
      "epoch [1/2], loss:0.0108\n",
      "epoch [2/2], loss:0.0755\n",
      "epoch [1/2], loss:0.1043\n",
      "epoch [2/2], loss:0.0816\n",
      "epoch [1/2], loss:0.1271\n",
      "epoch [2/2], loss:0.1354\n",
      "epoch [1/2], loss:0.0122\n",
      "epoch [2/2], loss:0.0785\n",
      "epoch [1/2], loss:0.0791\n",
      "epoch [2/2], loss:0.0552\n",
      "epoch [1/2], loss:0.1190\n",
      "epoch [2/2], loss:0.0717\n",
      "epoch [1/2], loss:0.0878\n",
      "epoch [2/2], loss:0.0700\n",
      "epoch [1/2], loss:0.0495\n",
      "epoch [2/2], loss:0.0454\n",
      "epoch [1/2], loss:0.0803\n",
      "epoch [2/2], loss:0.0450\n",
      "epoch [1/2], loss:0.0137\n",
      "epoch [2/2], loss:0.0447\n",
      "epoch [1/2], loss:0.0688\n",
      "epoch [2/2], loss:0.0636\n",
      "epoch [1/2], loss:0.0784\n",
      "epoch [2/2], loss:0.0464\n",
      "epoch [1/2], loss:0.0864\n",
      "epoch [2/2], loss:0.0703\n",
      "epoch [1/2], loss:0.0768\n",
      "epoch [2/2], loss:0.0757\n",
      "epoch [1/2], loss:0.1071\n",
      "epoch [2/2], loss:0.2464\n",
      "epoch [1/2], loss:0.1860\n",
      "epoch [2/2], loss:0.1318\n",
      "epoch [1/2], loss:0.1576\n",
      "epoch [2/2], loss:0.1024\n",
      "epoch [1/2], loss:0.1637\n",
      "epoch [2/2], loss:0.3257\n",
      "epoch [1/2], loss:0.0975\n",
      "epoch [2/2], loss:0.0640\n",
      "epoch [1/2], loss:0.1469\n",
      "epoch [2/2], loss:0.0951\n",
      "epoch [1/2], loss:0.1144\n",
      "epoch [2/2], loss:0.0908\n",
      "epoch [1/2], loss:0.1130\n",
      "epoch [2/2], loss:0.0939\n",
      "epoch [1/2], loss:0.0956\n",
      "epoch [2/2], loss:0.0678\n",
      "epoch [1/2], loss:0.1415\n",
      "epoch [2/2], loss:0.1208\n",
      "epoch [1/2], loss:0.0963\n",
      "epoch [2/2], loss:0.1725\n",
      "epoch [1/2], loss:0.0938\n",
      "epoch [2/2], loss:0.1044\n",
      "epoch [1/2], loss:0.0931\n",
      "epoch [2/2], loss:0.0731\n",
      "epoch [1/2], loss:0.1053\n",
      "epoch [2/2], loss:0.0834\n",
      "epoch [1/2], loss:0.0706\n",
      "epoch [2/2], loss:0.0564\n",
      "epoch [1/2], loss:0.2967\n",
      "epoch [2/2], loss:0.1340\n",
      "epoch [1/2], loss:0.1767\n",
      "epoch [2/2], loss:0.2250\n",
      "epoch [1/2], loss:0.2681\n",
      "epoch [2/2], loss:0.1912\n",
      "epoch [1/2], loss:0.2026\n",
      "epoch [2/2], loss:0.1459\n",
      "epoch [1/2], loss:0.1287\n",
      "epoch [2/2], loss:0.0714\n",
      "epoch [1/2], loss:0.1123\n",
      "epoch [2/2], loss:0.2120\n",
      "epoch [1/2], loss:0.0884\n",
      "epoch [2/2], loss:0.1097\n",
      "epoch [1/2], loss:0.2023\n",
      "epoch [2/2], loss:0.0823\n",
      "epoch [1/2], loss:0.1067\n",
      "epoch [2/2], loss:0.0874\n",
      "epoch [1/2], loss:0.1001\n",
      "epoch [2/2], loss:0.0716\n"
     ]
    }
   ],
   "source": [
    "trainSpectra = []\n",
    "i = 0\n",
    "for key in TrainingKeys:\n",
    "    trainSpectra.append(torch.empty_like(TrainingSamples[key].spectra))\n",
    "    for j in range(TrainingSamples[key].spectra.size()[0]):\n",
    "        trainSpectra[i][j] = TrainingSamples[key].spectrum + TrainingSamples[key].spectra[j]\n",
    "    i += 1\n",
    "\n",
    "vb = TempVB()\n",
    "for i in range(70):\n",
    "    vb.crfAi.train(trainSpectra[i], epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "directed-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "borders = [0, 1, 2,\n",
    "           30, 31, 32,\n",
    "           40, 45, 50,\n",
    "           74, 75, 76,\n",
    "           82, 84, 86,\n",
    "           128, 129, 130\n",
    "          ]\n",
    "phonemes = [\"A\", \"N\", \"A\", \"T\", \"A\"]\n",
    "#offsets = [0, 5, 1, 1, 1]\n",
    "offsets = [0, 0, 0, 0, 0]\n",
    "\n",
    "sequence = VocalSequence(0, 400, vb, borders, phonemes, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "velvet-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "secret-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228a1b34610>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdRUlEQVR4nO3deZAe9X3n8ff3OebUOWgkCyQQeAWBEM4pgguMKytkAyaIzQYWauNVbcgqu4m9Zo/KymZry97ackhSa2+82UpKPjbaBBPwQSGfMVbATmIOj4Q4BUgICYQGzSAhNJLmeI7v/tH9jJ4ZzWj6ubs1n1cx1c/T0888X3pGn/nNt3/dbe6OiIic2VKtLkBERBpPYS8iMgco7EVE5gCFvYjIHKCwFxGZAzLNfLMlS5b4qlWrmvmWIiKJt23btnfdvbeWr9HUsF+1ahX9/f3NfEsRkcQzs321fg21cURE5gCFvYjIHDBr2JvZRWa2o+zjqJnda2Y9ZvaYme0Kl4ubUbCIiFRu1rB391fd/Qp3vwK4GjgBPAJsBLa6+2pga/hcRERiqNI2zhrgdXffB6wDNofrNwO317EuERGpo0rD/i7gwfDxMncfAAiXS6d7gZltMLN+M+sfGhqqvlIREala5LA3szbgNuCblbyBu29y9z537+vtrWmaqIiIVKmSkf3NwHZ3Pxg+P2hmywHC5WC9i5vq6T2HeO3gcKPfRkTkjFNJ2N/NyRYOwBZgffh4PfBovYqayb/Y9BQf/dLPGv02IiJnnEhhb2ZdwFrgO2Wr7wfWmtmu8HP31788ERGph0iXS3D3E8BZU9YdIpid03Tujpm14q1FRBIpkWfQPvGqZvWIiFQikWH/5J5DrS5BRCRREhP25TdG103SRUQqk5iwL5bl+/sjudYVIiKSQAkK+5Npf+SEwl5EpBKJCfvyzo3CXkSkMokJ+/KR/fHxfAsrERFJnsSEffnI/sR4oXWFiIgkUHLCnpNpf0IjexGRiiQm7Mtn44xoZC8iUpEEhb2XPW5hISIiCZSYsC9lfcomB7+IiMwuQWEfBHwmnaKgob2ISEUSE/alfM+mTCN7EZEKJSbsSyP7dMo0shcRqVBiwn5iZJ9OUXRdDE1EpBKJCfuTPfvgpiUa3IuIRJecsA+XmVRQslo5IiLRJSbsi6eM7BX2IiJRRb3h+CIz+5aZvWJmO83sQ2bWY2aPmdmucLm4kYWWBvKZVBD2GtmLiEQXdWT/p8CP3P2XgMuBncBGYKu7rwa2hs8bZqJnX2rjaGQvIhLZrGFvZguAG4CvAbj7uLsfAdYBm8PNNgO3N6bEQCnbJ9o4GtmLiEQWZWR/ATAE/F8ze9bMvmpm3cAydx8ACJdLG1jnyZ692jgiIhWLEvYZ4Crgz939SuA4FbRszGyDmfWbWf/Q0FCVZZ4c2bdn0gCM5YtVfy0RkbkmStjvB/a7+9Ph828RhP9BM1sOEC4Hp3uxu29y9z537+vt7a260NLIfsn8NgAOHx+v+muJiMw1s4a9u78DvGVmF4Wr1gAvA1uA9eG69cCjDakwVOraLOzMAjA8qhuYiIhElYm43aeAB8ysDdgD/GuCXxQPm9k9wJvAHY0pMVAa2WfTqUnPRURkdpHC3t13AH3TfGpNXas5jVwh6NF3ZIOefV4HaEVEIkvMGbT5QhDuHZlwZK+wFxGJLDlhXwxG9u3hyF5TL0VEoktM2OfCkX17OLJXG0dEJLrEhH1pJF8Kex2gFRGJLjFhXzpAWzqpSm0cEZHoEhP2pQO07Vldz15EpFLJCfuiRvYiItVKTNjnpo7s1bMXEYksMWE/9QCtRvYiItElJux1gFZEpHqJCfu8pl6KiFQtOWE/cW2c8KSqgsJeRCSqxIT9yTNogzaORvYiItElJuxPXhtHB2hFRCqVoLCfPLLXtXFERKJLTthPuRCaLnEsIhJdgsI+aOO0pXVSlYhIpRIT9rmik00bqZRhpp69iEglEhP2+UKRTCooN22msBcRqUBiwj5XcDJpAyCdMrVxREQqEOmG42a2FxgGCkDe3fvMrAd4CFgF7AXudPf3GlNm0LbJpMrCXidViYhEVsnI/tfc/Qp37wufbwS2uvtqYGv4vGHyxSKZ8OBsOmWaeikiUoFa2jjrgM3h483A7TVXcxq5gpMNR/bZdGriJCsREZld1LB34Mdmts3MNoTrlrn7AEC4XDrdC81sg5n1m1n/0NBQ1YXmCydH9tm06do4IiIViNSzB65z9wNmthR4zMxeifoG7r4J2ATQ19dXdULniicP0GbTKcYLGtmLiEQVaWTv7gfC5SDwCHANcNDMlgOEy8FGFQnByD4bTr1sS6cmLowmIiKzmzXszazbzOaXHgMfBV4EtgDrw83WA482qkgIZuOky3r2ubxG9iIiUUVp4ywDHjGz0vbfcPcfmdkvgIfN7B7gTeCOxpUZHqAttXEyNnHnKhERmd2sYe/ue4DLp1l/CFjTiKKmUz71MpNSz15EpBLJOoM2bOO0pVOajSMiUoHEhH2+UCRbmnqpNo6ISEUSE/aFKVMvFfYiItElJuzL2zjBPHu1cUREokpM2OeLJy9x3KaRvYhIRZIT9mWXOM6kbeLOVSIiMrvEhH2uWHaAVmfQiohUJDFhnz+lZ6+RvYhIVMkJ+7LZOG1pTb0UEalEcsK+7B60ujaOiEhlEhT2ZfPsM+rZi4hUIjFhP+kAbcrIFYu4bjouIhJJYsJ+6gFa9+CsWhERmV0iwt7dwwO0pWvjBEu1ckREoklE2JdG8OUje0DTL0VEIkpE2OdLYV829RLQ9EsRkYgSEfalUM+WTb0EdE17EZGIEhH2pVAvv8QxaGQvIhJVIsI+VwxCfeK2hGHoq2cvIhJNIsJ+6gHaNo3sRUQqEjnszSxtZs+a2ffC5z1m9piZ7QqXixtVZCns0zaljZNXz15EJIpKRvafBnaWPd8IbHX31cDW8HlDhF0cUqmTl0sAtXFERKKKFPZmtgL4OPDVstXrgM3h483A7XWtrEy+1LOfmGcfLHUDExGRaKKO7P8X8AdAebouc/cBgHC5dLoXmtkGM+s3s/6hoaGqiiyG18BJndKzVxtHRCSKWcPezG4FBt19WzVv4O6b3L3P3ft6e3ur+RKUBvClnn1GB2hFRCqSibDNdcBtZnYL0AEsMLO/Bg6a2XJ3HzCz5cBgo4qcOEAb/mrKauqliEhFZh3Zu/tn3H2Fu68C7gL+zt1/C9gCrA83Ww882qgiJ9o4pqmXIiLVqGWe/f3AWjPbBawNnzfEyZG9zqAVEalGlDbOBHd/AngifHwIWFP/kk5VmHKAVpc4FhGpTCLOoC2eclKVrnopIlKJRIT9KW2cVOkMWoW9iEgUyQj7KQdo1cYREalMIsK+dLmE9JQzaDX1UkQkmkSEfWlkPzHPPqWbl4iIVCIZYR8O7dNhyKdSRiZlOkArIhJRQsI+WJZm40Aw115hLyISTULCvjTP/uS6TNrUsxcRiSgRYV/0yVMvIbhkgkb2IiLRJCLsp96pCsI2ju5UJSISSSLCfur17AGyGZu4EbmIiJxeIsJ+xpG9pl6KiESSrLAvH9mnUrpcgohIRIkI++naOJm0TdybVkRETi8RYT/dPPuM2jgiIpElI+z91Hn22ZRG9iIiUSUi7Kdezx6CNo5G9iIi0SQi7EsHaDNlQ/tMKkVeJ1WJiESSqLCfermEfFEjexGRKJIR9tNcLiGT0gFaEZGoZg17M+sws2fM7Dkze8nMPh+u7zGzx8xsV7hc3KgiJ0b2k06qMrVxREQiijKyHwP+qbtfDlwB3GRm1wIbga3uvhrYGj5viOI0J1Vl0im1cUREIpo17D1wLHyaDT8cWAdsDtdvBm5vRIFQ1sYpH9lr6qWISGSRevZmljazHcAg8Ji7Pw0sc/cBgHC5dIbXbjCzfjPrHxoaqqrIYnGGM2jVsxcRiSRS2Lt7wd2vAFYA15jZpVHfwN03uXufu/f19vZWVWTBfVILB3QGrYhIJSqajePuR4AngJuAg2a2HCBcDta7uJJCcXILByCjNo6ISGRRZuP0mtmi8HEncCPwCrAFWB9uth54tEE1UnSfNMceSidVaWQvIhJFJsI2y4HNZpYm+OXwsLt/z8yeBB42s3uAN4E7GlVkoeinjOyzadNtCUVEIpo17N39eeDKadYfAtY0oqipCkWfdHAWdAatiEglEnEGbXGaA7Rt6TSFok+ccCUiIjOL0sZpuUvPWXjKzJv2bPB7aixfoKstEf8bIiItk4iUvLNvJXf2rZy0riMThn2uSFdbK6oSEUmORLRxptOeTQMwpvvQiojMKrlhH47sR3OFFlciIhJ/CQ57jexFRKJKbNh3lB2gFRGR00ts2GtkLyJJcHwsz/P7j3B0NNfSOpIb9tmTs3FEROLqlXeGue3P/pHt+95raR3JDXsdoBWRBCjdUa8t3dq4TWzYd2jqpYgkQOmE0GxGYV+V0sheB2hFJM5KF2zMTLnkS7MlOOw1sheR+BsPwz6rNk51Jkb26tmLSIyV7rvRpjZOdUo9+1GN7EUkxtTGqVFbRlMvRST+1MapUTplZNOmA7QiEmtq49RBeyatA7QiEmtq49RBRzalkb2IxFop7GM/z97MVprZ42a208xeMrNPh+t7zOwxM9sVLhc3vtzJ2jNpRtWzF5EYK51UlYQzaPPAf3L3i4Frgd83s0uAjcBWd18NbA2fN1V7JqU2jojEWi4pB2jdfcDdt4ePh4GdwDnAOmBzuNlm4PYG1TijtkxK8+xFJNZyhSJmwaSSVqroV42ZrQKuBJ4Glrn7AAS/EIClM7xmg5n1m1n/0NBQjeVO1p7VAVoRibfxQpFsqvWHRyNXYGbzgG8D97r70aivc/dN7t7n7n29vb3V1DijjowO0IpIvI3niy2fdgkRw97MsgRB/4C7fydcfdDMloefXw4MNqbEmbVn04zoAK2IxFhiwt7MDPgasNPdv1j2qS3A+vDxeuDR+pd3el3ZNKPjGtmLSHyN54stn4kDkImwzXXAJ4AXzGxHuO6zwP3Aw2Z2D/AmcEdDKjyNrrY0x8fzzX5bEZHIxgvxGNnPGvbu/g/ATIeR19S3nMp0tqUZ0cheRGIsMW2cOOtuz3BCYS8iMRaXNk7rK6hBZzbNSK5AseitLkVEZFpxaeO0voIadLUF17Qf0YlVIhJTY/nixM2WWqn1FdSgqz045KCDtCISV+rZ10FXeLcqHaQVkbga18i+dqU2jg7SikhcqWdfB50TYa82jojEk2bj1EF32LPXyF5E4ko9+zrozKqNIyLxpjZOHXSpjSMiMRe0cdKtLiPZYV9q4xwf08heROJJbZw6mBeG/bExjexFJH7cXW2ceuhqS5NJGUdHcq0uRUTkFOPh/Wc1z75GZsaCzizvK+xFJIbGw9umauplHSzoyHB0VG0cEYmfibDXyL52CzuzauOISCyV2jgK+zpQG0dE4kptnDpa0Jnl6KjCXkTiR22cOlrQoTaOiMTTaC4I+46sTqqqWdCzz+Ouu1WJSLyUbqxUOtu/lWYNezP7upkNmtmLZet6zOwxM9sVLhc3tsyZLejMMF4oTvwGFRGJi9KlXJIysv9L4KYp6zYCW919NbA1fN4SS7rbAXj32FirShARmdZoOLLvTELYu/vPgMNTVq8DNoePNwO317es6JbMbwMU9iISP6U2TmcS2jgzWObuAwDhculMG5rZBjPrN7P+oaGhKt9uZr3zOgAYGlbYi0i8jIwH7eVE9Oxr5e6b3L3P3ft6e3vr/vV75wdtnCGN7EUkZpLWs5/OQTNbDhAuB+tXUmXOmhe2cYbHW1WCiMi0EtWzn8EWYH34eD3waH3KqVw2naKnu42hY6OtKkFEZFojuQLplJFNW6tLiTT18kHgSeAiM9tvZvcA9wNrzWwXsDZ83jK989o5eHT6Ns6Trx/i+88PNLkiEZGgZ9+ZTWPW+rDPzLaBu989w6fW1LmWqq3s6eKtwyem/dzdX3kKgLWX3ByLU5ZFZO4YyeVjMRMHzoAzaAFWndXF3kPHTzmLttQvA3io/61mlyUic9zIeIGObDxiNh5V1Oi8Jd2M5ooMTpl+ufnneycef+H7Oxk8qr6+iDTPsbE889qzrS4DOEPCftVZXQC88e7xiXXuzlf+/g0+vHoJ3/vU9YzkCjy551CrShSROejoaJ75HbN2y5vijAj71UvnA7Bz4OjEuoNHx3j32BhrL1nGRR+YT1smRf/e91pVoojMQcOjeRZ0aGRfNx9Y2MHyhR1sf/PIxLpt+4Jgv3DZfLLpFLf+ynK+tW0/B46MtKhKEZlrhkdzLIjJyD4eVdTBVecuZvu+93B3zIzNP9/LOYs66TsvuCDnf1h7IT988R1u/OJP+fDqJbx1eIS9h47zV/dcw9Xn9bS4ehE5Ex0dyamNU2/Xr17C20dGeOHt93n8lUGe2XuY377+fDLh7cBW9nTx39f9MifGC/ztSwd5eeAoJ8YL/N4D2ykWdS18Eakvd+fYWJ75auPU1y2XLqczm+bz332Z+x55gdVL5/GJa8+btM0dfSt56fMf45nPruH1L9zCxpt/iYNHx/jST16btN1orsCnHnyWfYeOIyJSjePjBYqORvb1trAry30fv5hn33yPwyfG+cPf+JVpT6Lqbs+wdEEH6ZTxuzdcwG2Xn83//rvdvHTgfQB+sfcwN/zx43z3uQN85E+e4PhYvtn/KyJyBhgO740dl5F9PH7l1MlvXXseN168jPZMisXdbbNub2b811sv5uevv8vdm57i+tVL+MnLgyzsyrJsQXAJhs985wW+fPeVTaheRM4kh48HF2fs6Y5H2J8xI/uSDyzsiBT0JUvnd/DI713Hpecs5Ok9h/n4Zcv5wb//ME9/9kauOb+HH734DgX19EWkQoeOBWG/ZF57iysJnFEj+2qt7OniG//m2lPW/+bVK3jmjcPsO3ScC3rntaAyEUmq0t3zzopJ2J9xI/t6uurcRQA8tWfqXRlFRE7v5Mg+eqehkRT2p/HB3nmcs6iTn77WsnuziEhCvXt8jLZMinnt8WigKOxPw8y44cJe/nH3IXKFYqvLEZEEeef9UZbOb4/FtexBYT+rj1zYy7GxPNv36bo6IhLdvkMnOC+8SGMcKOxn8aEPnoWZ+vYiUpk3D5/g3B6FfWIs7Mxy+YpF/PDFgVNujiIiMp2jozkOHx/n3J7uVpcyQWEfwZ19K3nlnWF2vHWk1aWISAK8sD84I/+Ssxe0uJKTFPYR3HbF2XS3pfnK3++p6HXForPr4DBDw9PfDF1EzkylY3xXrFjU2kLK1DQnyMxuAv4USANfdff761JVzMxrz7Dhhg/ypZ+8xnefO8CvX372abcfHs3x/ecH+PLWXRx4f5SUwZqLl/EHH7uI1cvmN6lqEWkFd+eHL77D5SsWsrArHpdKgBrC3szSwP8B1gL7gV+Y2RZ3f7lexcXJ737kAv5h9xD3PrSDZ944zNpLlrF8YQcAg8Nj7B48xvP73+eFt4+we/AYRYdfPnsB/+7X/gkHjozw10/uY+2Xfsal5yzgshWLWLm4i/kdGTqzacYLRUZzBU6MFxjLFehqzzCvPcP8jmA5rz3DvI4MCzqyzGvP0N2emfYibyWFonNiPM/IeIHj4wWOj+U5MV7g2FiO4dE8RXd653WwdEE7Pd1tdGbTdGTTpFPxmCImklTuzoPPvMXLA0f5H7df2upyJrFqDzqa2YeAz7n7x8LnnwFw9z+c6TV9fX3e399f1fvFwfBoji/8YCff3vY249PMuz+ru43LVizkshWLuOHCJVx17uKJObbvHhvjm/37efzVQV59Z5j3R3I11dKeSZFNpyi6Uyg67gSPPXhcjUzKSJlB8B/BQwuXwXkHE+tt+vVM2j54fVTlX2/Suil1JEFSDuUnZc6BJ2CPusOREzmOjeW55vwevvE7vzpxP41amdk2d++r6WvUEPa/Cdzk7r8TPv8E8Kvu/skp220ANgCce+65V+/bt6+WemPh/ZEcOweOMhj24pfMa+P8Jd18YEFHpBMo3J0T4Yh7NFekLZOiLZOiqy1NeybFSK7AsdE8w2N5jo3mOTaWZzhcHhvNTTzPF52UQcqMVMomHqdTRndbhs62NN3tabraMnS1pZkf/mWQMhgaHmNweIzDx8cZzRUYzRUZywfX33ac8D88/OURPA4+5x6un7qOUniUtom+T0/9GtPUEX4uJueozCohZcbmpJ/ZJKHK+R0ZLluxiFsvX057Jl23r1uPsK+lZz/dvj/ln7e7bwI2QTCyr+H9YmNhZ5ZrLzir6tebGd1hO2Y6QThnWFr1O8xOF3YTmVtq+RtjP7Cy7PkK4EBt5YiISCPUEva/AFab2flm1gbcBWypT1kiIlJPVbdx3D1vZp8E/pZg6uXX3f2lulUmIiJ1U9M8e3f/AfCDOtUiIiINojNoRUTmAIW9iMgcoLAXEZkDFPYiInNA1WfQVvVmZkNAtafQLgHerWM59Rbn+uJcG6i+WsS5NlB9tSiv7Tx3763lizU17GthZv21ni7cSHGuL861geqrRZxrA9VXi3rXpjaOiMgcoLAXEZkDkhT2m1pdwCziXF+cawPVV4s41waqrxZ1rS0xPXsREalekkb2IiJSJYW9iMgckIiwN7ObzOxVM9ttZhtb8P4rzexxM9tpZi+Z2afD9Z8zs7fNbEf4cUvZaz4T1vuqmX2sCTXuNbMXwjr6w3U9ZvaYme0Kl4ubXZ+ZXVS2f3aY2VEzu7eV+87Mvm5mg2b2Ytm6iveVmV0d7vPdZvZlq9Mtn2ao70/M7BUze97MHjGzReH6VWY2UrYf/6KR9c1QW8Xfyybvu4fKattrZjvC9c3edzPlSHN+9oLbzsX3g+Dyya8DFwBtwHPAJU2uYTlwVfh4PvAacAnwOeA/T7P9JWGd7cD5Yf3pBte4F1gyZd0fAxvDxxuBP2pVfWXfy3eA81q574AbgKuAF2vZV8AzwIcI7tr2Q+DmBtb3USATPv6jsvpWlW835evUvb4Zaqv4e9nMfTfl8/8T+G8t2ncz5UhTfvaSMLK/Btjt7nvcfRz4G2BdMwtw9wF33x4+HgZ2Auec5iXrgL9x9zF3fwPYTfD/0WzrgM3h483A7WXrW1HfGuB1dz/dWdQNr83dfwYcnuZ9I+8rM1sOLHD3Jz341/f/yl5T9/rc/cfung+fPkVwZ7gZNaq+GfbdTGKx70rC0e+dwIOn+xoN3Hcz5UhTfvaSEPbnAG+VPd/P6YO2ocxsFXAl8HS46pPhn9ZfL/vzqxU1O/BjM9tmwU3eAZa5+wAEP2gwcVvbVu3Tu5j8Dy0u+w4q31fnhI+bXSfAbxOM5krON7NnzeynZvbhcF2z66vke9mqffdh4KC77ypb15J9NyVHmvKzl4Swj3Rj82Yws3nAt4F73f0o8OfAB4ErgAGCPxGhNTVf5+5XATcDv29mN5xm26bXZ8GtK28DvhmuitO+O52Z6mlJnWZ2H5AHHghXDQDnuvuVwH8EvmFmC5pcX6Xfy1Z9j+9m8mCjJftumhyZcdMZ6qiqviSEfSxubG5mWYJv0APu/h0Adz/o7gV3LwJf4WS7oek1u/uBcDkIPBLWcjD8k6/0p+lgq+oj+CW03d0PhnXGZt+FKt1X+5ncSml4nWa2HrgV+Jfhn++Ef+IfCh9vI+jrXtjM+qr4XrZi32WA3wAeKqu76ftuuhyhST97SQj7lt/YPOz1fQ3Y6e5fLFu/vGyzfwaUZgBsAe4ys3YzOx9YTXBApVH1dZvZ/NJjgoN5L4Z1rA83Ww882or6QpNGVXHZd2Uq2lfhn9vDZnZt+PPxr8peU3dmdhPwX4Db3P1E2fpeM0uHjy8I69vTzPoq/V42e9+FbgRecfeJ9kez991MOUKzfvZqPcLcjA/gFoIj168D97Xg/a8n+DPpeWBH+HEL8FfAC+H6LcDystfcF9b7KnWaaXCa+i4gOGr/HPBSaR8BZwFbgV3hsqdF9XUBh4CFZetatu8IfukMADmCUdI91ewroI8g2F4H/ozwjPQG1beboH9b+vn7i3Dbfx5+z58DtgO/3sj6Zqit4u9lM/dduP4vgX87Zdtm77uZcqQpP3u6XIKIyByQhDaOiIjUSGEvIjIHKOxFROYAhb2IyBygsBcRmQMU9iIic4DCXkRkDvj/na3MTU/+mvMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.spectrum[42].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strange-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228da8bdf10>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sequence.synth.returnSignal.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
