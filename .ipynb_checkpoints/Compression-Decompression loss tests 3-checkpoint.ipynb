{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedData = torchaudio.load(\"a_a_i_a_u_e_a.wav\")\n",
    "tensor = loadedData[0][0]\n",
    "sampleRate = loadedData[1]\n",
    "del loadedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntransformedTensor = torch.stft(tensor, 8129, hop_length = 8129, win_length = 8129, return_complex = True)\\nbackTransformedTensor = torch.istft(transformedTensor, 8129, hop_length = 8129, win_length = 8129, length = 1036800)\\ntorchaudio.save(\"output.wav\", backTransformedTensor, sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)\\ndifference = backTransformedTensor - tensor\\nerror = difference/tensor\\nerror = error * torch.isfinite(error)\\nerror = torch.nan_to_num(error)\\nAmplitudes = transformedTensor.abs()\\nPhases = transformedTensor.angle()\\nElement = Amplitudes[0].transpose(0,1)[40]\\nmaximum = torch.max(Element, 0)\\nheight = maximum.values.item()\\ncenter = maximum.indices.item()\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "transformedTensor = torch.stft(tensor, 8129, hop_length = 8129, win_length = 8129, return_complex = True)\n",
    "backTransformedTensor = torch.istft(transformedTensor, 8129, hop_length = 8129, win_length = 8129, length = 1036800)\n",
    "torchaudio.save(\"output.wav\", backTransformedTensor, sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)\n",
    "difference = backTransformedTensor - tensor\n",
    "error = difference/tensor\n",
    "error = error * torch.isfinite(error)\n",
    "error = torch.nan_to_num(error)\n",
    "Amplitudes = transformedTensor.abs()\n",
    "Phases = transformedTensor.angle()\n",
    "Element = Amplitudes[0].transpose(0,1)[40]\n",
    "maximum = torch.max(Element, 0)\n",
    "height = maximum.values.item()\n",
    "center = maximum.indices.item()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchTensor = torchaudio.functional.detect_pitch_frequency(tensor, sampleRate, frame_time = 0.01, win_length = 10, freq_low = 85, freq_high = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitchTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedPitch = pitchTensor[250]\n",
    "searchRange = 0.2\n",
    "batchSize = math.floor((1. + searchRange) * sampleRate / expectedPitch)\n",
    "lowerSearchLimit = math.floor((1. - searchRange) * sampleRate / expectedPitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchStart = 0\n",
    "deltas = torch.tensor([], dtype = int)\n",
    "while batchStart + batchSize <= tensor.size()[0]:\n",
    "    \n",
    "    sample = torch.index_select(tensor, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "    zeroTransitions = torch.tensor([], dtype = int)\n",
    "    for i in range(lowerSearchLimit, batchSize):\n",
    "        if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "            zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            \n",
    "    error = math.inf\n",
    "    delta = math.floor(sampleRate / expectedPitch)\n",
    "    for i in zeroTransitions:\n",
    "        shiftedSample = torch.index_select(tensor, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "        newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "        if error > newError:\n",
    "            delta = i.item()\n",
    "            error = newError\n",
    "            \n",
    "    deltas = torch.cat([deltas, torch.tensor([delta])])\n",
    "    batchStart += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchStart = 0\n",
    "batchEnd = deltas[0].item()\n",
    "\n",
    "nFormants = 10\n",
    "formants = torch.empty(deltas.size()[0], nFormants, dtype=torch.cfloat)\n",
    "residualCurve = torch.tensor([], dtype = float)\n",
    "\n",
    "for i in range(deltas.size()[0]):\n",
    "    batch = torch.index_select(tensor, 0, torch.linspace(batchStart, batchEnd, batchEnd - batchStart, dtype = int))\n",
    "    fft = torch.fft.fft(batch)\n",
    "    formants[i] = torch.index_select(fft, 0, torch.linspace(0, nFormants, nFormants, dtype = int))\n",
    "    residualBatch = torch.cat([torch.zeros(nFormants, dtype=torch.cfloat), torch.index_select(fft, 0, torch.linspace(nFormants, fft.size()[0]-1, fft.size()[0]-1 - nFormants, dtype = int))], 0)\n",
    "    residualCurve = torch.cat([residualCurve, torch.fft.ifft(residualBatch, n = batchEnd-batchStart)], 0)\n",
    "    batchStart += deltas[i].item()\n",
    "    batchEnd += deltas[min(i + 1, deltas.size()[0]-1)].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchStart = 0\n",
    "batchEnd = deltas[0].item()\n",
    "formantCurve = torch.tensor([], dtype = float)\n",
    "for i in range(deltas.size()[0]):\n",
    "    formantBatch = torch.fft.ifft(formants[i], n = batchEnd-batchStart)\n",
    "    formantCurve = torch.cat([formantCurve, formantBatch], 0)\n",
    "    batchStart += deltas[i].item()\n",
    "    batchEnd += deltas[min(i + 1, deltas.size()[0]-1)].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCurve = (formantCurve * 1.) + (residualCurve * 1.)\n",
    "torchaudio.save(\"output_2.wav\", torch.unsqueeze(finalCurve.real, 0), sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
