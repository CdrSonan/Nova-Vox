{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSample:\n",
    "    def __init__(self, filepath):\n",
    "        loadedData = torchaudio.load(filepath)\n",
    "        self.waveform = loadedData[0][0]\n",
    "        self.sampleRate = loadedData[1]\n",
    "        del loadedData\n",
    "        self.pitchDeltas = torch.tensor([], dtype = int)\n",
    "        self.pitchBorders = torch.tensor([], dtype = int)\n",
    "        self.Pitch = torch.tensor([0], dtype = int)\n",
    "        self.spectra = torch.tensor([[]], dtype = float)\n",
    "        self.spectrum = torch.tensor([], dtype = float)\n",
    "        self.excitation = torch.tensor([], dtype = float) #replace with periodic and aperiodic excitation once implemented\n",
    "        \n",
    "        self.MainOsc = torch.tensor([], dtype = float)\n",
    "        \n",
    "    def CalculatePitch(self, expectedPitch, searchRange = 0.2):\n",
    "        batchSize = math.floor((1. + searchRange) * self.sampleRate / expectedPitch)\n",
    "        lowerSearchLimit = math.floor((1. - searchRange) * self.sampleRate / expectedPitch)\n",
    "        batchStart = 0\n",
    "        while batchStart + batchSize <= self.waveform.size()[0] - batchSize:\n",
    "            sample = torch.index_select(self.waveform, 0, torch.linspace(batchStart, batchStart + batchSize, batchSize, dtype = int))\n",
    "            zeroTransitions = torch.tensor([], dtype = int)\n",
    "            for i in range(lowerSearchLimit, batchSize):\n",
    "                if (sample[i-1] < 0) and (sample[i] > 0):\n",
    "                    zeroTransitions = torch.cat([zeroTransitions, torch.tensor([i])], 0)\n",
    "            error = math.inf\n",
    "            delta = math.floor(self.sampleRate / expectedPitch)\n",
    "            for i in zeroTransitions:\n",
    "                shiftedSample = torch.index_select(self.waveform, 0, torch.linspace(batchStart + i.item(), batchStart + batchSize + i.item(), batchSize, dtype = int))\n",
    "                newError = torch.sum(torch.pow(sample - shiftedSample, 2))\n",
    "                if error > newError:\n",
    "                    delta = i.item()\n",
    "                    error = newError\n",
    "            self.pitchDeltas = torch.cat([self.pitchDeltas, torch.tensor([delta])])\n",
    "            batchStart += delta\n",
    "        nBatches = self.pitchDeltas.size()[0]\n",
    "        self.pitchBorders = torch.zeros(nBatches + 1, dtype = int)\n",
    "        for i in range(nBatches):\n",
    "            self.pitchBorders[i+1] = self.pitchBorders[i] + self.pitchDeltas[i]\n",
    "        self.Pitch = torch.mean(self.pitchDeltas.float()).int()\n",
    "        del batchSize\n",
    "        del lowerSearchLimit\n",
    "        del batchStart\n",
    "        del sample\n",
    "        del zeroTransitions\n",
    "        del error\n",
    "        del delta\n",
    "        del shiftedSample\n",
    "        del newError\n",
    "        del nBatches\n",
    "    def CalculateSpectra(self, iterations = 10, filterWidth = 20):\n",
    "        Window = torch.hann_window(self.Pitch * 3)\n",
    "        signals = torch.stft(self.waveform, self.Pitch * 3, hop_length = self.Pitch, win_length = self.Pitch * 3, window = Window, return_complex = True)\n",
    "        \n",
    "        f0 = signals[3]\n",
    "        f1 = signals[6]\n",
    "       \n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        \n",
    "        self.MainOsc = torch.empty(self.waveform.size()[0])\n",
    "        for i in range(self.waveform.size()[0]):\n",
    "            self.MainOsc[i] = f0.abs() * math.sin(2 * math.pi * i / self.Pitch + f0.angle())\n",
    "            self.MainOsc[i] += f1.abs() * math.sin(4 * math.pi * i / self.Pitch + f1.angle())\n",
    "            \n",
    "            EnvSin = math.pow(math.sin(i * 0.5 * math.pi / self.pitch - math.pi / 4), 2)\n",
    "            EnvCos = math.pow(math.cos(i * 0.5 * math.pi / self.pitch - math.pi / 4), 2)\n",
    "            \n",
    "            self.MainOsc[i] = \n",
    "        \n",
    "        self.waveform -= self.MainOsc\n",
    "        \n",
    "        signals = torch.stft(self.waveform, self.Pitch * 3, hop_length = self.Pitch, win_length = self.Pitch * 3, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        \n",
    "        workingSpectra = signals.abs()\n",
    "        self.spectra = torch.full_like(workingSpectra, -float(\"inf\"), dtype=torch.float)\n",
    "        for i in range(iterations):\n",
    "            workingSpectra = torch.max(workingSpectra, self.spectra)\n",
    "            self.spectra = workingSpectra\n",
    "            for i in range(filterWidth):\n",
    "                self.spectra = torch.roll(workingSpectra, -i, dims = 1) + self.spectra + torch.roll(workingSpectra, i, dims = 1)\n",
    "            self.spectra = self.spectra / (2 * filterWidth + 1)\n",
    "        self.spectrum = torch.mean(self.spectra, 0)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.spectra[i] = self.spectra[i] - self.spectrum\n",
    "        del Window\n",
    "        del signals\n",
    "        del workingSpectra\n",
    "    def CalculateExcitation(self):\n",
    "        Window = torch.hann_window(self.Pitch * 3)\n",
    "        signals = torch.stft(self.waveform, self.Pitch * 3, hop_length = self.Pitch, win_length = self.Pitch * 3, window = Window, return_complex = True)\n",
    "        signals = torch.transpose(signals, 0, 1)\n",
    "        excitations = torch.empty_like(signals)\n",
    "        for i in range(excitations.size()[0]):\n",
    "            excitations[i] = signals[i] / (self.spectrum + self.spectra[i])\n",
    "        excitations = torch.transpose(excitations, 0, 1)\n",
    "        self.excitation = torch.istft(excitations, self.Pitch * 3, hop_length = self.Pitch, win_length = self.Pitch * 3, window = Window, onesided = True)\n",
    "        del Window\n",
    "        del signals\n",
    "        del excitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesizer:\n",
    "    def __init__(self, Excitation, Spectrum, Spectra, SampleRate):\n",
    "        self.excitation = Excitation\n",
    "        self.spectrum = Spectrum\n",
    "        self.spectra = Spectra\n",
    "        self.sampleRate = SampleRate\n",
    "        self.returnSignal = torch.tensor([], dtype = float)\n",
    "    def Synthesize(self, pitch, steadiness):\n",
    "        Window = torch.hann_window(pitch * 3)\n",
    "        self.returnSignal = torch.stft(self.excitation, pitch * 3, hop_length = pitch, win_length = pitch * 3, window = Window, return_complex = True)\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        for i in range(self.spectra.size()[0]):\n",
    "            self.returnSignal[i] = self.returnSignal[i] * (self.spectrum + math.pow(1 - steadiness, 2) * torch.roll(self.spectra, 0, dims=0)[i])\n",
    "        self.returnSignal = torch.transpose(self.returnSignal, 0, 1)\n",
    "        self.returnSignal = torch.istft(self.returnSignal, pitch * 3, hop_length = pitch, win_length = pitch * 3, window = Window, onesided=True, )\n",
    "        del Window\n",
    "    def save(self, filepath):\n",
    "        torchaudio.save(filepath, torch.unsqueeze(self.returnSignal, 0), self.sampleRate, format=\"wav\", encoding=\"PCM_S\", bits_per_sample=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecCrfAi(nn.Module):\n",
    "    def __init__(self, inputsize, learningRate=1e-5):\n",
    "        super(SpecCrfAi, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Conv2d(1, 10, (51, 3), padding = (25, 0), bias = True)\n",
    "        self.PReLu1 = nn.PReLU(num_parameters=10, init=0.1)\n",
    "        self.layer2 = torch.nn.Conv2d(10, 10, (51, 1), padding = (25, 0), bias = True)\n",
    "        self.PReLu2 = nn.PReLU(num_parameters=10, init=0.1)\n",
    "        self.layer3 = torch.nn.Conv2d(10, 10, (51, 1), padding = (25, 0), bias = True)\n",
    "        self.PReLu3 = nn.PReLU(num_parameters=10, init=0.1)\n",
    "        self.layer4 = torch.nn.Conv2d(10, 1, (51, 1), padding = (25, 0), bias = True)\n",
    "        \n",
    "        self.learningRate = learningRate\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=0.)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        \n",
    "    def forward(self, spectrum1, spectrum2, factor):\n",
    "        fac = torch.full((spectrum1.size()[0], 1), factor)\n",
    "        x = torch.cat((spectrum1.unsqueeze(1), fac, spectrum2.unsqueeze(1)), dim = 1)\n",
    "        x = x.float().unsqueeze(0).unsqueeze(0)\n",
    "        x = self.layer1(x)\n",
    "        x = self.PReLu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.PReLu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.PReLu3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "    def processData(self, spectrum1, spectrum2, factor):\n",
    "        spectrum1 = torch.log(spectrum1)\n",
    "        spectrum2 = torch.log(spectrum2)\n",
    "        output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "        output = torch.exp(output)\n",
    "        return output\n",
    "    \n",
    "    def train(self, indata, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            for data in self.dataLoader(indata):\n",
    "                spectrum1 = data[0]\n",
    "                spectrum2 = data[-1]\n",
    "                spectrum1 = torch.log(spectrum1)\n",
    "                spectrum2 = torch.log(spectrum2)\n",
    "                indexList = numpy.arange(0, data.size()[0], 1)\n",
    "                numpy.random.shuffle(indexList)\n",
    "                for i in indexList:\n",
    "                    factor = i / float(data.size()[0])\n",
    "                    spectrumTarget = data[i]\n",
    "                    spectrumTarget = torch.log(spectrumTarget)\n",
    "                    output = torch.squeeze(self(spectrum1, spectrum2, factor))\n",
    "                    loss = self.criterion(output, spectrumTarget)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "            print('epoch [{}/{}], loss:{:.4f}'\n",
    "                  .format(epoch + 1, epochs, loss.data))\n",
    "            \n",
    "    def dataLoader(self, data):\n",
    "        return torch.utils.data.DataLoader(dataset=data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-314-97a8936e51ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maudioSample1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Samples/a_a.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0maudioSample1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalculatePitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m95.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0maudioSample1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalculateSpectra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maudioSample1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalculateExcitation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-311-2febb8f3ae77>\u001b[0m in \u001b[0;36mCalculateSpectra\u001b[1;34m(self, iterations, filterWidth)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMainOsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMainOsc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPitch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMainOsc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPitch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "audioSample1 = AudioSample(\"Samples/a_a.wav\")\n",
    "audioSample1.CalculatePitch(95.)\n",
    "audioSample1.CalculateSpectra()\n",
    "audioSample1.CalculateExcitation()\n",
    "\n",
    "audioSample2 = AudioSample(\"Samples/a_i.wav\")\n",
    "audioSample2.CalculatePitch(95.)\n",
    "audioSample2.CalculateSpectra()\n",
    "audioSample2.CalculateExcitation()\n",
    "\n",
    "audioSample3 = AudioSample(\"Samples/a_u.wav\")\n",
    "audioSample3.CalculatePitch(95.)\n",
    "audioSample3.CalculateSpectra()\n",
    "audioSample3.CalculateExcitation()\n",
    "\n",
    "audioSample4 = AudioSample(\"Samples/e_a.wav\")\n",
    "audioSample4.CalculatePitch(95.)\n",
    "audioSample4.CalculateSpectra()\n",
    "audioSample4.CalculateExcitation()\n",
    "\n",
    "audioSample5 = AudioSample(\"Samples/i_a.wav\")\n",
    "audioSample5.CalculatePitch(95.)\n",
    "audioSample5.CalculateSpectra()\n",
    "audioSample5.CalculateExcitation()\n",
    "\n",
    "audioSample6 = AudioSample(\"Samples/u_e.wav\")\n",
    "audioSample6.CalculatePitch(95.)\n",
    "audioSample6.CalculateSpectra()\n",
    "audioSample6.CalculateExcitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = Synthesizer(audioSample4.excitation, audioSample4.spectrum, audioSample4.spectra, audioSample4.sampleRate)\n",
    "synthesizer.Synthesize(audioSample4.Pitch, 1.)\n",
    "synthesizer.save(\"Output_high_Steadiness.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSpectra = torch.empty_like(audioSample4.spectra)\n",
    "for i in range(audioSample4.spectra.size()[0]):\n",
    "    trainSpectra[i] = audioSample4.spectrum + audioSample4.spectra[i]\n",
    "specCrfAi = SpecCrfAi(trainSpectra.size()[1])\n",
    "specCrfAi.train(trainSpectra, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = specCrfAi.processData(trainSpectra[0], trainSpectra[-1], 0.5).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.log(trainSpectra[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.log(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((trainSpectra[10] - output) / (trainSpectra[10]) + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
